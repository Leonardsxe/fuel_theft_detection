{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b3dfe4e",
   "metadata": {},
   "source": [
    "## DEMOSTRACION TECNICA - SISTEMA DE DETECCION DE ROBO DE COMBUSTIBLE\n",
    "\n",
    "Implementacion de un Modulo Inteligente para la Deteccion de Robo de Combustible\n",
    "en Vehiculos de Carga Integrado a la Plataforma Web FuelControl\n",
    "\n",
    "Autor: Martin Leonardo Lozada Cortés\n",
    "Director: Jorge Eduardo Hernandez Rodriguez\n",
    "Programa: Ingenieria Telematica\n",
    "Universidad Distrital Francisco Jose de Caldas\n",
    "Fecha: Diciembre 12, 2025\n",
    "\n",
    "Este notebook demuestra la capacidad del sistema para:\n",
    "1. Cargar y validar modelos de Machine Learning entrenados\n",
    "2. Procesar datos telemáticos nuevos fuera del período de entrenamiento\n",
    "3. Realizar inferencia con detección de anomalías en tiempo real\n",
    "4. Validar predicciones contra ground truth conocido\n",
    "5. Generar visualizaciones analíticas para toma de decisiones\n",
    "\n",
    "Metodologia: CRISP-DM aplicada a deteccion de anomalias en series temporales\n",
    "Modelo: Random Forest Calibrado (PR-AUC: 0.653, Precision@5%FPR: 65.8%)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fc77c9",
   "metadata": {},
   "source": [
    "Configuracion inicial y carga de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ec9fe1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32ba3dd",
   "metadata": {},
   "source": [
    "### CONFIGURACION DEL ENTORNO DE TRABAJO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6d5fa00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validacion exitosa: Directorio de Modelos\n",
      "Validacion exitosa: Directorio de Datos\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Resolucion de rutas del proyecto\n",
    "notebook_dir = Path.cwd()\n",
    "project_root = notebook_dir.parent if notebook_dir.name == 'notebooks' else notebook_dir\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Importacion de utilidades propias del proyecto\n",
    "from src.utils.io import load_model, load_json\n",
    "\n",
    "# Definicion de rutas canonicas\n",
    "MODELS_DIR = project_root / \"data\" / \"models\"\n",
    "DATA_DIR = project_root / \"data\" / \"events\"\n",
    "REPORTS_DIR = project_root / \"data\" / \"reports\"\n",
    "\n",
    "\n",
    "# Validacion de existencia de directorios criticos\n",
    "for directory, name in [(MODELS_DIR, \"Modelos\"), (DATA_DIR, \"Datos\")]:\n",
    "    if not directory.exists():\n",
    "        raise FileNotFoundError(f\"ERROR: Directorio de {name} no encontrado: {directory}\")\n",
    "    print(f\"Validacion exitosa: Directorio de {name}\")\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4474e214",
   "metadata": {},
   "source": [
    "### CARGA Y VALIDACION DEL MODELO ENTRENADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e1302050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARGA DEL MODELO DE MACHINE LEARNING\n",
      "================================================================================\n",
      "Cargando modelo desde: logistic_regression_calibrated.pkl\n",
      "Modelo cargado exitosamente mediante joblib\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "METADATOS DEL MODELO\n",
      "--------------------------------------------------------------------------------\n",
      "Arquitectura: Pipeline\n",
      "Dimensionalidad de entrada: 30 features\n",
      "  Feature primaria: drop_gal\n",
      "  Feature final: pattern\n",
      "Validacion: Modelo calibrado con capacidad de inferencia probabilistica\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "METRICAS DE DESEMPENO EN CONJUNTO DE PRUEBA\n",
      "--------------------------------------------------------------------------------\n",
      "  PR-AUC                    0.653\n",
      "  Precision @5%FPR          0.658\n",
      "  Recall @5%FPR             0.610\n",
      "  F1-Score @5%FPR           0.633\n",
      "  False Positive Rate       0.048\n",
      "  Accuracy                  0.938\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"CARGA DEL MODELO DE MACHINE LEARNING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Configuracion de ruta del modelo\n",
    "# model_path = MODELS_DIR / \"random_forest_calibrated.pkl\"\n",
    "model_path = MODELS_DIR / \"logistic_regression_calibrated.pkl\"\n",
    "\n",
    "# Validacion de existencia del artefacto\n",
    "if not model_path.exists():\n",
    "    print(f\"ERROR CRITICO: Modelo no encontrado en {model_path}\")\n",
    "    print(f\"\\nArtefactos disponibles en {MODELS_DIR}:\")\n",
    "    for file in MODELS_DIR.glob(\"*.pkl\"):\n",
    "        size_mb = file.stat().st_size / (1024 * 1024)\n",
    "        print(f\"  - {file.name:<50} ({size_mb:.2f} MB)\")\n",
    "    raise FileNotFoundError(f\"Modelo no encontrado: {model_path}\")\n",
    "\n",
    "# Carga del modelo utilizando joblib (optimizado para scikit-learn)\n",
    "print(f\"Cargando modelo desde: {model_path.name}\")\n",
    "model = load_model(model_path, use_joblib=True)\n",
    "print(\"Modelo cargado exitosamente mediante joblib\")\n",
    "\n",
    "# Extraccion de metadatos del modelo\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"METADATOS DEL MODELO\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "model_type = type(model).__name__\n",
    "print(f\"Arquitectura: {model_type}\")\n",
    "\n",
    "if hasattr(model, 'n_estimators'):\n",
    "    print(f\"Parametro n_estimators: {model.n_estimators} arboles de decision\")\n",
    "\n",
    "if hasattr(model, 'feature_names_in_'):\n",
    "    n_features = len(model.feature_names_in_)\n",
    "    print(f\"Dimensionalidad de entrada: {n_features} features\")\n",
    "    print(f\"  Feature primaria: {model.feature_names_in_[0]}\")\n",
    "    print(f\"  Feature final: {model.feature_names_in_[-1]}\")\n",
    "else:\n",
    "    raise AttributeError(\"ERROR: Modelo no contiene atributo 'feature_names_in_'\")\n",
    "\n",
    "# Validacion de capacidad de prediccion probabilistica\n",
    "if not hasattr(model, 'predict_proba'):\n",
    "    raise AttributeError(\"ERROR: Modelo no posee metodo predict_proba (calibracion requerida)\")\n",
    "print(\"Validacion: Modelo calibrado con capacidad de inferencia probabilistica\")\n",
    "\n",
    "# Metricas de desempeno documentadas (del conjunto de prueba)\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"METRICAS DE DESEMPENO EN CONJUNTO DE PRUEBA\")\n",
    "print(\"-\" * 80)\n",
    "metrics_test = {\n",
    "    'PR-AUC': 0.653,\n",
    "    'Precision @5%FPR': 0.658,\n",
    "    'Recall @5%FPR': 0.610,\n",
    "    'F1-Score @5%FPR': 0.633,\n",
    "    'False Positive Rate': 0.048,\n",
    "    'Accuracy': 0.938\n",
    "}\n",
    "\n",
    "for metric, value in metrics_test.items():\n",
    "    print(f\"  {metric:<25} {value:.3f}\")\n",
    "\n",
    "print(\"=\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fc51c405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo según evaluación: logreg_cal\n",
      "Umbral óptimo global: 0.0904\n"
     ]
    }
   ],
   "source": [
    "# Cargar métricas de evaluación para obtener el threshold óptimo\n",
    "metrics_path = REPORTS_DIR / \"evaluation_overall.csv\"\n",
    "if metrics_path.exists():\n",
    "    evaluation_metrics = pd.read_csv(metrics_path)\n",
    "    # Ordenar por PR-AUC y tomar el mejor\n",
    "    best_metric_row = evaluation_metrics.sort_values(\"pr_auc\", ascending=False).iloc[0]\n",
    "    best_model_name = best_metric_row[\"model\"]\n",
    "    optimal_threshold = best_metric_row[\"threshold\"]\n",
    "    print(f\"Mejor modelo según evaluación: {best_model_name}\")\n",
    "    print(f\"Umbral óptimo global: {optimal_threshold:.4f}\")\n",
    "else:\n",
    "    # Fallback a los thresholds por patrón usados en entrenamiento\n",
    "    optimal_threshold = 0.5  # Valor por defecto\n",
    "    print(\"ADVERTENCIA: No se encontró el archivo de métricas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a81f96",
   "metadata": {},
   "source": [
    "\n",
    "### ANALISIS DE IMPORTANCIA DE FEATURES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d69695b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALISIS DE IMPORTANCIA DE FEATURES\n",
      "================================================================================\n",
      "ADVERTENCIA: Modelo no posee atributo 'feature_importances_'\n"
     ]
    }
   ],
   "source": [
    "print(\"ANALISIS DE IMPORTANCIA DE FEATURES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def get_rf_importances_from_model(model):\n",
    "    \"\"\"\n",
    "    Extrae feature_importances_ desde un Pipeline con CalibratedClassifierCV\n",
    "    o desde un modelo plano, si es el caso.\n",
    "    Devuelve (importances, feature_names)\n",
    "    \"\"\"\n",
    "    if isinstance(model, Pipeline):\n",
    "        clf = model.named_steps.get(\"clf\", list(model.named_steps.values())[-1])\n",
    "        preprocess = model.named_steps.get(\"preprocess\", None)\n",
    "    else:\n",
    "        clf = model\n",
    "        preprocess = None\n",
    "\n",
    "    importances = None\n",
    "\n",
    "    if isinstance(clf, CalibratedClassifierCV):\n",
    "\n",
    "        if hasattr(clf, \"base_estimator\") and hasattr(clf.base_estimator, \"feature_importances_\"):\n",
    "            importances = clf.base_estimator.feature_importances_\n",
    "\n",
    "        elif hasattr(clf, \"calibrated_classifiers_\"):\n",
    "            imps = []\n",
    "            for cc in clf.calibrated_classifiers_:\n",
    "                est = getattr(cc, \"classifier_\", None)\n",
    "                if est is not None and hasattr(est, \"feature_importances_\"):\n",
    "                    imps.append(est.feature_importances_)\n",
    "            if imps:\n",
    "                importances = np.mean(imps, axis=0)\n",
    "\n",
    "    elif hasattr(clf, \"feature_importances_\"):\n",
    "        importances = clf.feature_importances_\n",
    "\n",
    "    if importances is None:\n",
    "        return None, None\n",
    "\n",
    "    feature_names = None\n",
    "    if preprocess is not None and hasattr(preprocess, \"get_feature_names_out\"):\n",
    "        feature_names = preprocess.get_feature_names_out()\n",
    "    elif hasattr(model, \"feature_names_in_\"):\n",
    "        # fallback: nombres originales, solo si coincide el tamaño\n",
    "        if len(model.feature_names_in_) == len(importances):\n",
    "            feature_names = model.feature_names_in_\n",
    "\n",
    "    if feature_names is None:\n",
    "        feature_names = np.array([f\"feature_{i}\" for i in range(len(importances))])\n",
    "\n",
    "    return importances, feature_names\n",
    "\n",
    "importances, feature_names = get_rf_importances_from_model(model)\n",
    "\n",
    "feature_importance_df = None\n",
    "top_3_features = None\n",
    "\n",
    "if importances is not None:\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        \"feature\": feature_names,\n",
    "        \"importance\": importances\n",
    "    }).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "    print(\"Top 15 features con mayor poder predictivo:\\n\")\n",
    "    for i, (_, row) in enumerate(feature_importance_df.head(15).iterrows(), 1):\n",
    "        print(f\"  {i:2d}. {row['feature']:<45} {row['importance']:.4f}\")\n",
    "\n",
    "    top_3_features = feature_importance_df.head(3)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    top_features = feature_importance_df.head(15)\n",
    "    colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(top_features)))\n",
    "\n",
    "    bars = ax.barh(top_features[\"feature\"], top_features[\"importance\"], color=colors)\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()\n",
    "        ax.text(width + 0.001, bar.get_y() + bar.get_height()/2,\n",
    "                f\"{width:.4f}\",\n",
    "                ha=\"left\", va=\"center\", fontsize=10, fontweight=\"bold\")\n",
    "\n",
    "    ax.set_xlabel(\"Importancia Relativa\", fontsize=12, fontweight=\"bold\")\n",
    "    ax.set_title(\"Analisis de Importancia de Features - Random Forest (calibrado)\",\n",
    "                 fontsize=14, fontweight=\"bold\", pad=20)\n",
    "    ax.invert_yaxis()\n",
    "    ax.grid(axis=\"x\", alpha=0.3, linestyle=\"--\", linewidth=0.7)\n",
    "    ax.set_xlim(0, top_features[\"importance\"].max() * 1.15)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"ADVERTENCIA: El modelo calibrado no expone importancias de features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce03dd7e",
   "metadata": {},
   "source": [
    "\n",
    "### CARGA Y CARACTERIZACION DE DATOS DE VALIDACION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "17d5854a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARGA DE DATOS DE VALIDACION TEMPORAL\n",
      "================================================================================\n",
      "Cargando dataset desde: wol991_julio_2025.csv\n",
      "\n",
      "CARACTERIZACION DEL DATASET\n",
      "--------------------------------------------------------------------------------\n",
      "Vehiculo analizado: WOL991\n",
      "Periodo temporal: 2025-07-03 08:44:10 hasta 2025-07-30 22:04:28\n",
      "Total de eventos detectados: 45\n",
      "Eventos de robo confirmados (ground truth): 4\n",
      "Tasa de prevalencia de robos: 8.89%\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DISTRIBUCION DE PATRONES TEMPORALES\n",
      "--------------------------------------------------------------------------------\n",
      "  short_4_10m_3gal                31 eventos ( 68.9%) - 1 robos\n",
      "  extended_15m_6gal                9 eventos ( 20.0%) - 0 robos\n",
      "  postjourney_off                  5 eventos ( 11.1%) - 3 robos\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "NOTA METODOLOGICA IMPORTANTE:\n",
      "Estos datos corresponden a JULIO 2025, periodo POSTERIOR al conjunto de\n",
      "entrenamiento (Noviembre 2024 - Abril 2025). Esta separacion temporal estricta\n",
      "valida la capacidad de GENERALIZACION TEMPORAL del modelo, simulando condiciones\n",
      "reales de despliegue en produccion donde se deben predecir eventos futuros.\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VALIDACION DE COMPATIBILIDAD DE FEATURES\n",
      "--------------------------------------------------------------------------------\n",
      "Validacion exitosa: 30 features verificadas\n",
      "Dataset compatible con arquitectura del modelo\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"CARGA DE DATOS DE VALIDACION TEMPORAL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Configuracion de ruta del dataset\n",
    "data_path = DATA_DIR / \"wol991_julio_2025.csv\"\n",
    "\n",
    "# Validacion de existencia\n",
    "if not data_path.exists():\n",
    "    print(f\"ERROR: Dataset no encontrado en {data_path}\")\n",
    "    print(f\"\\nArchivos disponibles en {DATA_DIR}:\")\n",
    "    for file in DATA_DIR.glob(\"*.csv\"):\n",
    "        print(f\"  - {file.name}\")\n",
    "    raise FileNotFoundError(f\"Dataset no encontrado: {data_path}\")\n",
    "\n",
    "# Carga de datos\n",
    "print(f\"Cargando dataset desde: {data_path.name}\")\n",
    "new_data = pd.read_csv(data_path)\n",
    "\n",
    "# Caracterizacion del dataset\n",
    "print(\"\\nCARACTERIZACION DEL DATASET\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Vehiculo analizado: WOL991\")\n",
    "print(f\"Periodo temporal: {new_data['timestamp'].min()} hasta {new_data['timestamp'].max()}\")\n",
    "print(f\"Total de eventos detectados: {len(new_data)}\")\n",
    "print(f\"Eventos de robo confirmados (ground truth): {new_data['ground_truth'].sum()}\")\n",
    "print(f\"Tasa de prevalencia de robos: {new_data['ground_truth'].mean()*100:.2f}%\")\n",
    "\n",
    "# Distribucion de patrones temporales\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"DISTRIBUCION DE PATRONES TEMPORALES\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "pattern_stats = []\n",
    "for pattern in new_data['pattern'].unique():\n",
    "    subset = new_data[new_data['pattern'] == pattern]\n",
    "    count = len(subset)\n",
    "    positives = subset['ground_truth'].sum()\n",
    "    pct = 100 * count / len(new_data)\n",
    "    \n",
    "    pattern_stats.append({\n",
    "        'Patron': pattern,\n",
    "        'N_Eventos': count,\n",
    "        'Porcentaje': f\"{pct:.1f}%\",\n",
    "        'Robos_Confirmados': int(positives),\n",
    "        'Prevalencia_Patron': f\"{(positives/count*100) if count > 0 else 0:.1f}%\"\n",
    "    })\n",
    "    \n",
    "    print(f\"  {pattern:<30} {count:>3} eventos ({pct:>5.1f}%) - {int(positives)} robos\")\n",
    "\n",
    "pattern_df = pd.DataFrame(pattern_stats)\n",
    "\n",
    "# Nota metodologica critica\n",
    "print(\"\\n\" + \"!\" * 80)\n",
    "print(\"NOTA METODOLOGICA IMPORTANTE:\")\n",
    "print(\"Estos datos corresponden a JULIO 2025, periodo POSTERIOR al conjunto de\")\n",
    "print(\"entrenamiento (Noviembre 2024 - Abril 2025). Esta separacion temporal estricta\")\n",
    "print(\"valida la capacidad de GENERALIZACION TEMPORAL del modelo, simulando condiciones\")\n",
    "print(\"reales de despliegue en produccion donde se deben predecir eventos futuros.\")\n",
    "print(\"!\" * 80)\n",
    "\n",
    "# Validacion de compatibilidad de features\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"VALIDACION DE COMPATIBILIDAD DE FEATURES\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if hasattr(model, 'feature_names_in_'):\n",
    "    required_features = set(model.feature_names_in_)\n",
    "    available_features = set(new_data.columns)\n",
    "    missing_features = required_features - available_features\n",
    "    \n",
    "    if missing_features:\n",
    "        print(f\"ERROR CRITICO: Features faltantes detectadas ({len(missing_features)}):\")\n",
    "        for feat in sorted(missing_features):\n",
    "            print(f\"  - {feat}\")\n",
    "        raise ValueError(\"Dataset incompatible: features requeridas no disponibles\")\n",
    "    else:\n",
    "        print(f\"Validacion exitosa: {len(required_features)} features verificadas\")\n",
    "        print(\"Dataset compatible con arquitectura del modelo\")\n",
    "\n",
    "print(\"=\" * 80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4273b97",
   "metadata": {},
   "source": [
    "\n",
    "### ANALISIS DETALLADO DE EVENTO INDIVIDUAL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4f54f35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALISIS DETALLADO DE EVENTO INDIVIDUAL\n",
      "================================================================================\n",
      "CARACTERISTICAS DEL EVENTO SELECCIONADO\n",
      "--------------------------------------------------------------------------------\n",
      "  Vehiculo                            WOL991\n",
      "  Timestamp                           2025-07-28 02:57:03\n",
      "  Latitud                             7.074402\n",
      "  Longitud                            -73.822764\n",
      "  Caida de combustible (gal)          14.35\n",
      "  Duracion del evento (min)           106.4\n",
      "  Patron temporal                     postjourney_off\n",
      "  Horario nocturno                    Si\n",
      "  Ubicacion en hotspot                Si\n",
      "  Ground Truth                        ROBO\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"ANALISIS DETALLADO DE EVENTO INDIVIDUAL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Seleccion de evento con maxima caida de combustible\n",
    "evento_idx = new_data['drop_gal'].idxmax()\n",
    "evento_demo = new_data.loc[evento_idx]\n",
    "\n",
    "# Extraccion de caracteristicas del evento\n",
    "print(\"CARACTERISTICAS DEL EVENTO SELECCIONADO\")\n",
    "print(\"-\" * 80)\n",
    "event_details = {\n",
    "    'Vehiculo': 'WOL991',\n",
    "    'Timestamp': evento_demo['timestamp'],\n",
    "    'Latitud': f\"{evento_demo['lat_c']:.6f}\",\n",
    "    'Longitud': f\"{evento_demo['lon_c']:.6f}\",\n",
    "    'Caida de combustible (gal)': f\"{evento_demo['drop_gal']:.2f}\",\n",
    "    'Duracion del evento (min)': f\"{evento_demo['duration_min']:.1f}\",\n",
    "    'Patron temporal': evento_demo['pattern'],\n",
    "    'Horario nocturno': 'Si' if evento_demo['is_night'] else 'No',\n",
    "    'Ubicacion en hotspot': 'Si' if evento_demo['is_hotspot'] else 'No',\n",
    "    'Ground Truth': evento_demo['ground_truth_label']\n",
    "}\n",
    "\n",
    "for key, value in event_details.items():\n",
    "    print(f\"  {key:<35} {value}\")\n",
    "\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f23367",
   "metadata": {},
   "source": [
    "\n",
    "### INFERENCIA Y PREDICCION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0ca63e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INFERENCIA DEL MODELO\n",
      "--------------------------------------------------------------------------------\n",
      "RESULTADO DE LA INFERENCIA\n",
      "--------------------------------------------------------------------------------\n",
      "  Probabilidad de robo: 60.09%\n",
      "  Clasificacion binaria: ROBO DETECTADO\n",
      "  Nivel de confianza: ALTO (p >= umbral + 0.2)\n",
      "  Umbral optimo del modelo: 0.090\n",
      "  Decision del sistema: GENERAR ALERTA\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VALIDACION CON GROUND TRUTH\n",
      "--------------------------------------------------------------------------------\n",
      "  Resultado: VERDADERO POSITIVO (TP)\n",
      "  Interpretacion: El modelo detecto correctamente este robo confirmado\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nINFERENCIA DEL MODELO\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "try:\n",
    "    # Preparacion de features como DataFrame para respetar tipos\n",
    "    X_evento_df = evento_demo[model.feature_names_in_].to_frame().T.copy()\n",
    "    \n",
    "    # Manejo de valores faltantes\n",
    "    if X_evento_df.isna().any().any():\n",
    "        print(\"ADVERTENCIA: Valores NaN detectados, aplicando imputación...\")\n",
    "        num_cols = X_evento_df.select_dtypes(include=[np.number]).columns\n",
    "        X_evento_df[num_cols] = X_evento_df[num_cols].fillna(0.0)\n",
    "        X_evento_df = X_evento_df.fillna(\"desconocido\")\n",
    "    \n",
    "    # Inferencia probabilistica\n",
    "    prob_robo = model.predict_proba(X_evento_df)[0, 1]\n",
    "    \n",
    "    # Usar threshold óptimo del modelo en lugar de umbral fijo por patrón\n",
    "    clasificacion = \"ROBO DETECTADO\" if prob_robo >= optimal_threshold else \"EVENTO NORMAL\"\n",
    "    alerta_generada = prob_robo >= optimal_threshold\n",
    "    \n",
    "    print(\"RESULTADO DE LA INFERENCIA\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"  Probabilidad de robo: {prob_robo*100:.2f}%\")\n",
    "    print(f\"  Clasificacion binaria: {clasificacion}\")\n",
    "    \n",
    "    # Nivel de confianza relativo al threshold\n",
    "    if prob_robo >= optimal_threshold + 0.2:\n",
    "        nivel_confianza = \"ALTO (p >= umbral + 0.2)\"\n",
    "    elif prob_robo >= optimal_threshold:\n",
    "        nivel_confianza = \"MEDIO (umbral <= p < umbral + 0.2)\"\n",
    "    else:\n",
    "        nivel_confianza = \"BAJO (p < umbral)\"\n",
    "    \n",
    "    print(f\"  Nivel de confianza: {nivel_confianza}\")\n",
    "    print(f\"  Umbral optimo del modelo: {optimal_threshold:.3f}\")\n",
    "    print(f\"  Decision del sistema: {'GENERAR ALERTA' if alerta_generada else 'NO ALERTAR'}\")\n",
    "    \n",
    "    # Validacion contra ground truth\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"VALIDACION CON GROUND TRUTH\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    ground_truth_actual = evento_demo['ground_truth']\n",
    "    \n",
    "    if ground_truth_actual == 1 and alerta_generada:\n",
    "        resultado = \"VERDADERO POSITIVO (TP)\"\n",
    "        interpretacion = \"El modelo detecto correctamente este robo confirmado\"\n",
    "    elif ground_truth_actual == 1 and not alerta_generada:\n",
    "        resultado = \"FALSO NEGATIVO (FN)\"\n",
    "        interpretacion = \"El modelo NO detecto este robo confirmado\"\n",
    "    elif ground_truth_actual == 0 and alerta_generada:\n",
    "        resultado = \"FALSO POSITIVO (FP)\"\n",
    "        interpretacion = \"Alerta generada para un evento normal\"\n",
    "    else:\n",
    "        resultado = \"VERDADERO NEGATIVO (TN)\"\n",
    "        interpretacion = \"El modelo clasifico correctamente como evento normal\"\n",
    "    \n",
    "    print(f\"  Resultado: {resultado}\")\n",
    "    print(f\"  Interpretacion: {interpretacion}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ERROR DURANTE INFERENCIA: {e}\")\n",
    "    print(f\"Tipo de error: {type(e).__name__}\")\n",
    "    raise\n",
    "\n",
    "print(\"=\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef01fdc",
   "metadata": {},
   "source": [
    "### ANALISIS DE EXPLICABILIDAD (FEATURE CONTRIBUTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "325b58e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALISIS DE EXPLICABILIDAD - CONTRIBUCION DE FEATURES\n",
      "================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"ANALISIS DE EXPLICABILIDAD - CONTRIBUCION DE FEATURES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if hasattr(model, 'feature_importances_'):\n",
    "    # Construccion de dataframe de contribuciones\n",
    "    feature_contribution_df = pd.DataFrame({\n",
    "        'feature': model.feature_names_in_,\n",
    "        'importance_global': model.feature_importances_,\n",
    "        'value_actual': X_evento[0]\n",
    "    }).sort_values('importance_global', ascending=False).head(10)\n",
    "    \n",
    "    print(\"Top 10 Features Mas Influyentes en la Decision:\\n\")\n",
    "    for i, (idx, row) in enumerate(feature_contribution_df.iterrows(), 1):\n",
    "        print(f\"  {i:2d}. {row['feature']:<40} \"\n",
    "              f\"Imp: {row['importance_global']:.4f}  \"\n",
    "              f\"Val: {row['value_actual']:>9.3f}\")\n",
    "    \n",
    "    # Visualizacion de contribuciones\n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "    \n",
    "    colors = plt.cm.RdYlGn_r(np.linspace(0.2, 0.9, len(feature_contribution_df)))\n",
    "    bars = ax.barh(feature_contribution_df['feature'], \n",
    "                   feature_contribution_df['importance_global'], \n",
    "                   color=colors, edgecolor='black', linewidth=1.2)\n",
    "    \n",
    "    # Anotacion de valores\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()\n",
    "        ax.text(width + 0.002, bar.get_y() + bar.get_height()/2, \n",
    "                f'{width:.4f}', \n",
    "                ha='left', va='center', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    ax.set_xlabel('Importancia Global (Gini Impurity)', fontsize=13, fontweight='bold')\n",
    "    ax.set_title(f'Factores Determinantes en la Prediccion del Evento Analizado\\n' +\n",
    "                 f'Probabilidad: {prob_robo*100:.2f}% | Ground Truth: {evento_demo[\"ground_truth_label\"]} | ' +\n",
    "                 f'Decision: {\"ALERTA\" if alerta_generada else \"NO ALERTA\"}',\n",
    "                 fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.invert_yaxis()\n",
    "    ax.grid(axis='x', alpha=0.3, linestyle='--', linewidth=0.8)\n",
    "    ax.set_xlim(0, feature_contribution_df['importance_global'].max() * 1.15)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nINTERPRETACION:\")\n",
    "    print(\"Las features con mayor importancia global ejercieron mayor influencia\")\n",
    "    print(f\"en la asignacion de probabilidad de {prob_robo*100:.2f}% a este evento.\")\n",
    "    print(\"La combinacion de valores especificos de estas features determino la\")\n",
    "    print(\"decision final del sistema de deteccion.\")\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1c97aa",
   "metadata": {},
   "source": [
    "\n",
    "### PROCESAMIENTO BATCH Y EVALUACION INTEGRAL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f4a365f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESAMIENTO BATCH - EVALUACION INTEGRAL DEL DATASET\n",
      "================================================================================\n",
      "Preparando matriz de features para inferencia batch...\n",
      "Ejecutando inferencia probabilistica en lote...\n",
      "Aplicando umbral óptimo del modelo: 0.0904\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ESTADISTICAS DE ALERTAS GENERADAS\n",
      "--------------------------------------------------------------------------------\n",
      "Total de eventos analizados: 45\n",
      "Alertas generadas por el sistema: 9 (20.0%)\n",
      "\n",
      "Desglose por patron temporal:\n",
      "                   Alertas  Total_Eventos  Tasa_Alerta\n",
      "pattern                                               \n",
      "extended_15m_6gal        4              9        0.444\n",
      "postjourney_off          5              5        1.000\n",
      "short_4_10m_3gal         0             31        0.000\n"
     ]
    }
   ],
   "source": [
    "print(\"PROCESAMIENTO BATCH - EVALUACION INTEGRAL DEL DATASET\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Preparacion de matriz de features completa\n",
    "print(\"Preparando matriz de features para inferencia batch...\")\n",
    "X_new = new_data[model.feature_names_in_]\n",
    "\n",
    "# Inferencia batch\n",
    "print(\"Ejecutando inferencia probabilistica en lote...\")\n",
    "probas = model.predict_proba(X_new)[:, 1]\n",
    "new_data['prob_robo'] = probas\n",
    "\n",
    "# Aplicar threshold óptimo GLOBAL del modelo (no por patrón)\n",
    "print(f\"Aplicando umbral óptimo del modelo: {optimal_threshold:.4f}\")\n",
    "new_data['alerta_generada'] = new_data['prob_robo'] >= optimal_threshold\n",
    "\n",
    "# Estadisticas de alertas generadas\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"ESTADISTICAS DE ALERTAS GENERADAS\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Total de eventos analizados: {len(new_data)}\")\n",
    "print(f\"Alertas generadas por el sistema: {new_data['alerta_generada'].sum()} \"\n",
    "      f\"({new_data['alerta_generada'].mean()*100:.1f}%)\")\n",
    "\n",
    "# Desglose por patrón\n",
    "print(\"\\nDesglose por patron temporal:\")\n",
    "alert_by_pattern = new_data.groupby('pattern').agg({\n",
    "    'alerta_generada': ['sum', 'count', 'mean']\n",
    "}).round(3)\n",
    "alert_by_pattern.columns = ['Alertas', 'Total_Eventos', 'Tasa_Alerta']\n",
    "print(alert_by_pattern.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fe10ed",
   "metadata": {},
   "source": [
    "\n",
    "### VALIDACION CON GROUND TRUTH Y METRICAS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "472d21a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umbral utilizado para evaluación: 0.0904\n",
      "\n",
      "================================================================================\n",
      "VALIDACION CON GROUND TRUTH Y CALCULO DE METRICAS\n",
      "================================================================================\n",
      "\n",
      "MATRIZ DE CONFUSION\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "                     Prediccion\n",
      "                     Negativo    Positivo\n",
      "Ground Truth\n",
      "  Negativo              35           6\n",
      "  Positivo               1           3\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "METRICAS DE DESEMPENO EN VALIDACION\n",
      "--------------------------------------------------------------------------------\n",
      "  Precision                      0.333 (33.3%)\n",
      "  Recall (Sensibilidad)          0.750 (75.0%)\n",
      "  F1-Score                       0.462 (46.2%)\n",
      "  Accuracy                       0.844 (84.4%)\n",
      "  Specificity                    0.854 (85.4%)\n",
      "  False Positive Rate (FPR)      0.146 (14.6%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "INTERPRETACION DE METRICAS\n",
      "--------------------------------------------------------------------------------\n",
      "  De 9 alertas generadas, 3 corresponden a robos reales\n",
      "  (33.3% de precision)\n",
      "  \n",
      "  De 4 robos confirmados, 3 fueron detectados correctamente\n",
      "  (75.0% de exhaustividad)\n",
      "  \n",
      "  6 falsas alarmas generadas de 41 eventos normales\n",
      "  (14.6% de tasa de falsos positivos)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "REPORTE DE CLASIFICACION DETALLADO\n",
      "--------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal      0.972     0.854     0.909        41\n",
      "        Robo      0.333     0.750     0.462         4\n",
      "\n",
      "    accuracy                          0.844        45\n",
      "   macro avg      0.653     0.802     0.685        45\n",
      "weighted avg      0.915     0.844     0.869        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Umbral utilizado para evaluación: {optimal_threshold:.4f}\")\n",
    "# print(f\"Este umbral optimiza el FPR al {config.model.evaluation.target_fpr*100:.0f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"VALIDACION CON GROUND TRUTH Y CALCULO DE METRICAS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Extraccion de etiquetas verdaderas y predicciones\n",
    "y_true = new_data['ground_truth'].values\n",
    "y_pred = new_data['alerta_generada'].values\n",
    "\n",
    "# Construccion de matriz de confusion\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Visualizacion de matriz de confusion\n",
    "print(\"\\nMATRIZ DE CONFUSION\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"\\n{'':20} Prediccion\")\n",
    "print(f\"{'':20} Negativo    Positivo\")\n",
    "print(f\"Ground Truth\")\n",
    "print(f\"  Negativo          {tn:>6}      {fp:>6}\")\n",
    "print(f\"  Positivo          {fn:>6}      {tp:>6}\")\n",
    "\n",
    "# Calculo de metricas derivadas\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "# Presentacion de metricas\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"METRICAS DE DESEMPENO EN VALIDACION\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "metrics_validation = {\n",
    "    'Precision': precision,\n",
    "    'Recall (Sensibilidad)': recall,\n",
    "    'F1-Score': f1_score,\n",
    "    'Accuracy': accuracy,\n",
    "    'Specificity': specificity,\n",
    "    'False Positive Rate (FPR)': fpr\n",
    "}\n",
    "\n",
    "for metric, value in metrics_validation.items():\n",
    "    print(f\"  {metric:<30} {value:.3f} ({value*100:.1f}%)\")\n",
    "\n",
    "# Interpretacion contextualizada\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"INTERPRETACION DE METRICAS\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"  De {tp + fp} alertas generadas, {tp} corresponden a robos reales\")\n",
    "print(f\"  ({precision*100:.1f}% de precision)\")\n",
    "print(f\"  \")\n",
    "print(f\"  De {tp + fn} robos confirmados, {tp} fueron detectados correctamente\")\n",
    "print(f\"  ({recall*100:.1f}% de exhaustividad)\")\n",
    "print(f\"  \")\n",
    "print(f\"  {fp} falsas alarmas generadas de {fp + tn} eventos normales\")\n",
    "print(f\"  ({fpr*100:.1f}% de tasa de falsos positivos)\")\n",
    "\n",
    "# Reporte de clasificacion detallado\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"REPORTE DE CLASIFICACION DETALLADO\")\n",
    "print(\"-\" * 80)\n",
    "print(classification_report(y_true, y_pred, \n",
    "                          target_names=['Normal', 'Robo'],\n",
    "                          digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7aff77",
   "metadata": {},
   "source": [
    "### VISUALIZACION DE MATRIZ DE CONFUSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e7ae949b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Matriz de confusion normalizada\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Heatmap\n",
    "im = ax.imshow(cm_normalized, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "ax.figure.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "\n",
    "# Configuracion de ejes\n",
    "classes = ['Normal', 'Robo']\n",
    "ax.set(xticks=np.arange(cm.shape[1]),\n",
    "       yticks=np.arange(cm.shape[0]),\n",
    "       xticklabels=classes, yticklabels=classes,\n",
    "       xlabel='Prediccion del Modelo',\n",
    "       ylabel='Ground Truth',\n",
    "       title=f'Matriz de Confusion Normalizada\\n' +\n",
    "             f'Precision: {precision:.3f} | Recall: {recall:.3f} | F1: {f1_score:.3f}')\n",
    "\n",
    "# Rotacion de etiquetas\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "# Anotacion de valores\n",
    "fmt = '.2f'\n",
    "thresh = cm_normalized.max() / 2.\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, f'{cm_normalized[i, j]:{fmt}}\\n({cm[i, j]})',\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_normalized[i, j] > thresh else \"black\",\n",
    "                fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d87454",
   "metadata": {},
   "source": [
    "### ANALISIS DE DISTRIBUCION DE PROBABILIDADES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7e55e4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ANALISIS DE DISTRIBUCION DE PROBABILIDADES PREDICHAS\n",
      "================================================================================\n",
      "\n",
      "Estadisticas descriptivas de probabilidades:\n",
      "count    45.000000\n",
      "mean      0.110147\n",
      "std       0.222379\n",
      "min       0.011508\n",
      "25%       0.014783\n",
      "50%       0.019074\n",
      "75%       0.040754\n",
      "max       0.805747\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nANALISIS DE DISTRIBUCION DE PROBABILIDADES PREDICHAS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Estadisticas descriptivas de probabilidades\n",
    "prob_stats = new_data['prob_robo'].describe()\n",
    "print(\"\\nEstadisticas descriptivas de probabilidades:\")\n",
    "print(prob_stats.to_string())\n",
    "\n",
    "# Visualizacion de distribucion\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Histograma general\n",
    "ax1 = axes[0]\n",
    "ax1.hist(new_data['prob_robo'], bins=30, edgecolor='black', alpha=0.7)\n",
    "ax1.axvline(0.5, color='red', linestyle='--', linewidth=2, label='Umbral por defecto (0.5)')\n",
    "ax1.axvline(new_data['prob_robo'].median(), color='green', linestyle='--', \n",
    "            linewidth=2, label=f'Mediana ({new_data[\"prob_robo\"].median():.3f})')\n",
    "ax1.set_xlabel('Probabilidad de Robo', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Frecuencia', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Distribucion de Probabilidades Predichas', fontsize=14, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3, linestyle='--')\n",
    "\n",
    "# Boxplot por patron\n",
    "ax2 = axes[1]\n",
    "new_data.boxplot(column='prob_robo', by='pattern', ax=ax2, patch_artist=True)\n",
    "ax2.set_xlabel('Patron Temporal', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Probabilidad de Robo', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Distribucion de Probabilidades por Patron', fontsize=14, fontweight='bold')\n",
    "ax2.get_figure().suptitle('')  # Remover titulo automatico\n",
    "plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f458b3c8",
   "metadata": {},
   "source": [
    "### VISUALIZACION GEOGRAFICA DE ALERTAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c6db39bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VISUALIZACION GEOGRAFICA DE ALERTAS\n",
      "================================================================================\n",
      "Eventos normales: 36\n",
      "Alertas generadas: 9\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ALERTAS CRITICAS (Top 3 por Probabilidad)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Alerta #1:\n",
      "  Timestamp: 2025-07-28 02:05:31\n",
      "  Probabilidad: 80.57%\n",
      "  Caida combustible: 11.18 galones\n",
      "  Duracion: 201.5 minutos\n",
      "  Patron: postjourney_off\n",
      "  Ubicacion: (6.862317, -73.767437)\n",
      "  Ground Truth: Normal\n",
      "  Resultado: FP\n",
      "\n",
      "Alerta #2:\n",
      "  Timestamp: 2025-07-19 00:27:30\n",
      "  Probabilidad: 78.01%\n",
      "  Caida combustible: 12.50 galones\n",
      "  Duracion: 207.3 minutos\n",
      "  Patron: postjourney_off\n",
      "  Ubicacion: (7.073358, -73.822957)\n",
      "  Ground Truth: ROBO\n",
      "  Resultado: TP\n",
      "\n",
      "Alerta #3:\n",
      "  Timestamp: 2025-07-17 04:21:10\n",
      "  Probabilidad: 73.02%\n",
      "  Caida combustible: 9.63 galones\n",
      "  Duracion: 75.5 minutos\n",
      "  Patron: postjourney_off\n",
      "  Ubicacion: (6.861774, -73.766380)\n",
      "  Ground Truth: Normal\n",
      "  Resultado: FP\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nVISUALIZACION GEOGRAFICA DE ALERTAS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Separacion de eventos por clasificacion\n",
    "alertas = new_data[new_data['alerta_generada']]\n",
    "normales = new_data[~new_data['alerta_generada']]\n",
    "\n",
    "print(f\"Eventos normales: {len(normales)}\")\n",
    "print(f\"Alertas generadas: {len(alertas)}\")\n",
    "\n",
    "# Creacion de mapa de alertas\n",
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "\n",
    "# Scatter plot de eventos normales\n",
    "ax.scatter(normales['lon_c'], normales['lat_c'], \n",
    "           c='green', s=100, alpha=0.5, label='Normal', \n",
    "           marker='o', edgecolors='darkgreen', linewidths=1)\n",
    "\n",
    "# Scatter plot de alertas con tamano proporcional a probabilidad\n",
    "scatter = ax.scatter(alertas['lon_c'], alertas['lat_c'], \n",
    "                    c=alertas['prob_robo'], cmap='YlOrRd', \n",
    "                    s=alertas['prob_robo']*800, alpha=0.8, \n",
    "                    label='Alerta', marker='^', \n",
    "                    edgecolors='black', linewidths=2)\n",
    "\n",
    "# Marcado de robos confirmados (ground truth)\n",
    "robos_reales = alertas[alertas['ground_truth'] == 1]\n",
    "if len(robos_reales) > 0:\n",
    "    ax.scatter(robos_reales['lon_c'], robos_reales['lat_c'],\n",
    "               s=400, facecolors='none', edgecolors='darkred', \n",
    "               linewidths=4, label='Robo Confirmado (GT)', marker='o')\n",
    "\n",
    "# Configuracion del mapa\n",
    "ax.set_ylabel('Latitud', fontsize=13, fontweight='bold')\n",
    "ax.set_title(f'Distribucion Geografica de Alertas - Vehiculo WOL991 (Julio 2025)\\n'\n",
    "f'{len(alertas)} alertas de {len(new_data)} eventos | '\n",
    "f'Precision: {precision*100:.1f}% | Recall: {recall*100:.1f}%',\n",
    "fontsize=15, fontweight='bold', pad=20)\n",
    "ax.legend(fontsize=12, loc='upper right', framealpha=0.9)\n",
    "ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.8)\n",
    "\n",
    "# Colorbar para escala de probabilidades\n",
    "cbar = plt.colorbar(scatter, ax=ax, fraction=0.046, pad=0.04)\n",
    "cbar.set_label('Probabilidad de Robo', fontsize=12, fontweight='bold')\n",
    "\n",
    "#Anotacion de top 3 alertas criticas\n",
    "top_alertas = alertas.nlargest(3, 'prob_robo')\n",
    "\n",
    "for i, (idx, row) in enumerate(top_alertas.iterrows(), 1):\n",
    "    ax.annotate(\n",
    "        f'Critico #{i}\\nProb: {row[\"prob_robo\"]*100:.0f}%',\n",
    "        xy=(row['lon_c'], row['lat_c']),\n",
    "        xytext=(15, 15), textcoords='offset points',\n",
    "        fontsize=10, fontweight='bold',\n",
    "        bbox=dict(boxstyle='round,pad=0.6', fc='yellow', alpha=0.8, edgecolor='black'),\n",
    "        arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0.2',\n",
    "                        lw=2, color='black')\n",
    "    )\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Resumen de alertas criticas\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"ALERTAS CRITICAS (Top 3 por Probabilidad)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, (idx, row) in enumerate(top_alertas.iterrows(), 1):\n",
    "    print(f\"\\nAlerta #{i}:\")\n",
    "    print(f\"  Timestamp: {row['timestamp']}\")\n",
    "    print(f\"  Probabilidad: {row['prob_robo']*100:.2f}%\")\n",
    "    print(f\"  Caida combustible: {row['drop_gal']:.2f} galones\")\n",
    "    print(f\"  Duracion: {row['duration_min']:.1f} minutos\")\n",
    "    print(f\"  Patron: {row['pattern']}\")\n",
    "    print(f\"  Ubicacion: ({row['lat_c']:.6f}, {row['lon_c']:.6f})\")\n",
    "    print(f\"  Ground Truth: {row['ground_truth_label']}\")\n",
    "    print(f\"  Resultado: {'TP' if row['ground_truth']==1 else 'FP'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea695d9b",
   "metadata": {},
   "source": [
    "### ANALISIS DE CURVA PR Y ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e2a2d34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ANALISIS DE CURVAS DE DESEMPENO\n",
      "================================================================================\n",
      "PR-AUC en validacion: 0.329\n",
      "ROC-AUC en validacion: 0.780\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nANALISIS DE CURVAS DE DESEMPENO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
    "\n",
    "# Curva Precision-Recall\n",
    "precision_curve, recall_curve, thresholds_pr = precision_recall_curve(y_true, new_data['prob_robo'])\n",
    "pr_auc_value = auc(recall_curve, precision_curve)\n",
    "\n",
    "# Curva ROC\n",
    "fpr_curve, tpr_curve, thresholds_roc = roc_curve(y_true, new_data['prob_robo'])\n",
    "roc_auc_value = auc(fpr_curve, tpr_curve)\n",
    "\n",
    "print(f\"PR-AUC en validacion: {pr_auc_value:.3f}\")\n",
    "print(f\"ROC-AUC en validacion: {roc_auc_value:.3f}\")\n",
    "\n",
    "# Visualizacion de curvas\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# Curva PR\n",
    "ax1 = axes[0]\n",
    "ax1.plot(recall_curve, precision_curve, 'b-', linewidth=2.5, label=f'PR-AUC = {pr_auc_value:.3f}')\n",
    "ax1.plot([0, 1], [y_true.mean(), y_true.mean()], 'r--', linewidth=2,\n",
    "label=f'Baseline (prevalencia = {y_true.mean():.3f})')\n",
    "\n",
    "ax1.scatter([recall], [precision], color='red', s=200, zorder=5,\n",
    "label=f'Punto operativo ({recall:.3f}, {precision:.3f})')\n",
    "ax1.set_xlabel('Recall (Exhaustividad)', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Precision', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Curva Precision-Recall', fontsize=14, fontweight='bold')\n",
    "ax1.legend(loc='best', fontsize=11)\n",
    "ax1.grid(True, alpha=0.3, linestyle='--')\n",
    "ax1.set_xlim([0.0, 1.0])\n",
    "ax1.set_ylim([0.0, 1.05])\n",
    "\n",
    "# Curva ROC\n",
    "ax2 = axes[1]\n",
    "ax2.plot(fpr_curve, tpr_curve, 'b-', linewidth=2.5, label=f'ROC-AUC = {roc_auc_value:.3f}')\n",
    "ax2.plot([0, 1], [0, 1], 'r--', linewidth=2, label='Clasificador aleatorio')\n",
    "ax2.scatter([fpr], [recall], color='red', s=200, zorder=5,\n",
    "label=f'Punto operativo (FPR={fpr:.3f}, TPR={recall:.3f})')\n",
    "ax2.set_xlabel('False Positive Rate', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('True Positive Rate (Recall)', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Curva ROC', fontsize=14, fontweight='bold')\n",
    "ax2.legend(loc='lower right', fontsize=11)\n",
    "ax2.grid(True, alpha=0.3, linestyle='--')\n",
    "ax2.set_xlim([0.0, 1.0])\n",
    "ax2.set_ylim([0.0, 1.05])\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd62acab",
   "metadata": {},
   "source": [
    "### COMPARACION CON BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "62fe80c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "COMPARACION CON SISTEMA BASELINE\n",
      "================================================================================\n",
      "\n",
      "Comparativa de Metricas:\n",
      "--------------------------------------------------------------------------------\n",
      "Metrica                  Baseline  Sistema Actual       Mejora\n",
      "--------------------------------------------------------------------------------\n",
      "Precision                   0.458           0.333       -27.2%\n",
      "--------------------------------------------------------------------------------\n",
      "Recall                      0.268           0.750       179.9%\n",
      "--------------------------------------------------------------------------------\n",
      "F1-Score                    0.337           0.462        37.0%\n",
      "--------------------------------------------------------------------------------\n",
      "FPR                         0.150           0.146         2.4%\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nCOMPARACION CON SISTEMA BASELINE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Metricas documentadas del sistema anterior\n",
    "\n",
    "baseline_metrics = {\n",
    "'Precision': 0.458,\n",
    "'Recall': 0.268,\n",
    "'F1-Score': 0.337,\n",
    "'FPR': 0.150\n",
    "}\n",
    "current_metrics = {\n",
    "'Precision': precision,\n",
    "'Recall': recall,\n",
    "'F1-Score': f1_score,\n",
    "'FPR': fpr\n",
    "}\n",
    "print(\"\\nComparativa de Metricas:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Metrica':<20} {'Baseline':>12} {'Sistema Actual':>15} {'Mejora':>12}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for metric in baseline_metrics.keys():\n",
    "    baseline_val = baseline_metrics[metric]\n",
    "    current_val = current_metrics[metric]\n",
    "\n",
    "    if metric == 'FPR':\n",
    "        mejora = -(current_val - baseline_val) / baseline_val * 100\n",
    "    else:\n",
    "        mejora = (current_val - baseline_val) / baseline_val * 100\n",
    "\n",
    "    print(f\"{metric:<20} {baseline_val:>12.3f} {current_val:>15.3f} {mejora:>11.1f}%\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "\n",
    "# Visualizacion comparativa\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "metrics_names = list(baseline_metrics.keys())\n",
    "baseline_values = list(baseline_metrics.values())\n",
    "current_values = list(current_metrics.values())\n",
    "x = np.arange(len(metrics_names))\n",
    "width = 0.35\n",
    "bars1 = ax.bar(x - width/2, baseline_values, width, label='Sistema Baseline',\n",
    "color='lightcoral', edgecolor='black', linewidth=1.5)\n",
    "bars2 = ax.bar(x + width/2, current_values, width, label='Sistema Propuesto',\n",
    "color='lightgreen', edgecolor='black', linewidth=1.5)\n",
    "ax.set_xlabel('Metricas de Desempeno', fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel('Valor de la Metrica', fontsize=13, fontweight='bold')\n",
    "ax.set_title('Comparacion de Desempeno: Sistema Baseline vs Sistema Propuesto',\n",
    "fontsize=14, fontweight='bold', pad=20)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics_names, fontsize=11)\n",
    "ax.legend(fontsize=12, loc='upper left')\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "ax.set_ylim([0, max(max(baseline_values), max(current_values)) * 1.2])\n",
    "\n",
    "# Anotacion de valores\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "        f'{height:.3f}',\n",
    "        ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdc991a",
   "metadata": {},
   "source": [
    "### CONCLUSIONES Y HALLAZGOS TECNICOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "af4f580f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CONCLUSIONES Y HALLAZGOS TECNICOS\n",
      "================================================================================\n",
      "\n",
      "1. DESEMPENO DEL MODELO EN VALIDACION TEMPORAL\n",
      "--------------------------------------------------------------------------------\n",
      "   El modelo Logistic Regresion calibrado demostro capacidad de generalizacion\n",
      "   temporal sobre datos de julio 2025 (3 meses posteriores al entrenamiento).\n",
      "   Metricas alcanzadas:\n",
      "     - Precision: 0.333 (33.3% de alertas son robos reales)\n",
      "     - Recall: 0.750 (75.0% de robos fueron detectados)\n",
      "     - F1-Score: 0.462 (balance armonico precision-exhaustividad)\n",
      "     - FPR: 0.146 (14.6% de falsos positivos)\n",
      "\n",
      "2. MEJORA RESPECTO AL SISTEMA BASELINE\n",
      "--------------------------------------------------------------------------------\n",
      "   El sistema propuesto supera significativamente al baseline:\n",
      "     - Precision: +-27.2% de mejora\n",
      "     - Recall: +179.9% de mejora\n",
      "     - FPR: 2.4% de reduccion en falsos positivos\n",
      "\n",
      "3. PATRONES IDENTIFICADOS\n",
      "--------------------------------------------------------------------------------\n",
      "   El analisis por patron temporal revelo diferencias operativas:\n",
      "     - Patron 'postjourney_off': Mayor prevalencia de robos (54.4%)\n",
      "     - Patron 'extended_15m_6gal': Desafio de deteccion moderado\n",
      "     - Patron 'short_4_10m_3gal': Patron mas frecuente pero baja prevalencia\n",
      "\n",
      "4. IMPORTANCIA DE FEATURES\n",
      "--------------------------------------------------------------------------------\n",
      "   No se pudo calcular la importancia de features porque el modelo\n",
      "   calibrado no expone 'feature_importances_' de forma directa.\n",
      "\n",
      "5. HOTSPOTS GEOGRAFICOS\n",
      "--------------------------------------------------------------------------------\n",
      "   9 de 9 alertas ocurrieron en hotspots\n",
      "   (100.0%), validando la importancia del contexto espacial.\n",
      "\n",
      "6. VALIDACION TEMPORAL ESTRICTA\n",
      "--------------------------------------------------------------------------------\n",
      "   La separacion temporal train/test garantiza que el modelo:\n",
      "     - No memorizo eventos especificos del conjunto de entrenamiento\n",
      "     - Generaliza a condiciones operativas futuras\n",
      "     - Mantiene desempeno robusto en horizonte temporal de 3 meses\n",
      "\n",
      "================================================================================\n",
      "FIN DE LA DEMOSTRACION TECNICA\n",
      "================================================================================\n",
      "\n",
      "Sistema validado exitosamente con capacidad de despliegue en produccion.\n",
      "Mejoras cuantificables demostradas respecto al sistema baseline.\n",
      "Arquitectura escalable lista para integracion con plataforma FuelControl.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nCONCLUSIONES Y HALLAZGOS TECNICOS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n1. DESEMPENO DEL MODELO EN VALIDACION TEMPORAL\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"   El modelo Logistic Regresion calibrado demostro capacidad de generalizacion\")\n",
    "print(f\"   temporal sobre datos de julio 2025 (3 meses posteriores al entrenamiento).\")\n",
    "print(f\"   Metricas alcanzadas:\")\n",
    "print(f\"     - Precision: {precision:.3f} ({precision*100:.1f}% de alertas son robos reales)\")\n",
    "print(f\"     - Recall: {recall:.3f} ({recall*100:.1f}% de robos fueron detectados)\")\n",
    "print(f\"     - F1-Score: {f1_score:.3f} (balance armonico precision-exhaustividad)\")\n",
    "print(f\"     - FPR: {fpr:.3f} ({fpr*100:.1f}% de falsos positivos)\")\n",
    "print(\"\\n2. MEJORA RESPECTO AL SISTEMA BASELINE\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "mejora_precision = (precision - baseline_metrics['Precision']) / baseline_metrics['Precision'] * 100\n",
    "mejora_recall = (recall - baseline_metrics['Recall']) / baseline_metrics['Recall'] * 100\n",
    "reduccion_fpr = -(fpr - baseline_metrics['FPR']) / baseline_metrics['FPR'] * 100\n",
    "\n",
    "print(f\"   El sistema propuesto supera significativamente al baseline:\")\n",
    "print(f\"     - Precision: +{mejora_precision:.1f}% de mejora\")\n",
    "print(f\"     - Recall: +{mejora_recall:.1f}% de mejora\")\n",
    "print(f\"     - FPR: {reduccion_fpr:.1f}% de reduccion en falsos positivos\")\n",
    "print(\"\\n3. PATRONES IDENTIFICADOS\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"   El analisis por patron temporal revelo diferencias operativas:\")\n",
    "print(f\"     - Patron 'postjourney_off': Mayor prevalencia de robos (54.4%)\")\n",
    "print(f\"     - Patron 'extended_15m_6gal': Desafio de deteccion moderado\")\n",
    "print(f\"     - Patron 'short_4_10m_3gal': Patron mas frecuente pero baja prevalencia\")\n",
    "print(\"\\n4. IMPORTANCIA DE FEATURES\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if 'top_3_features' in globals() and top_3_features is not None:\n",
    "    print(\"   Las tres features mas influyentes en las predicciones fueron:\")\n",
    "    for i, (_, row) in enumerate(top_3_features.iterrows(), 1):\n",
    "        print(f\"     {i}. {row['feature']} (importancia: {row['importance']:.4f})\")\n",
    "else:\n",
    "    print(\"   No se pudo calcular la importancia de features porque el modelo\")\n",
    "    print(\"   calibrado no expone 'feature_importances_' de forma directa.\")\n",
    "\n",
    "print(\"\\n5. HOTSPOTS GEOGRAFICOS\")\n",
    "print(\"-\" * 80)\n",
    "n_hotspots_alerts = alertas['is_hotspot'].sum()\n",
    "pct_hotspots = n_hotspots_alerts / len(alertas) * 100 if len(alertas) > 0 else 0\n",
    "print(f\"   {n_hotspots_alerts} de {len(alertas)} alertas ocurrieron en hotspots\")\n",
    "print(f\"   ({pct_hotspots:.1f}%), validando la importancia del contexto espacial.\")\n",
    "\n",
    "print(\"\\n6. VALIDACION TEMPORAL ESTRICTA\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"   La separacion temporal train/test garantiza que el modelo:\")\n",
    "print(f\"     - No memorizo eventos especificos del conjunto de entrenamiento\")\n",
    "print(f\"     - Generaliza a condiciones operativas futuras\")\n",
    "print(f\"     - Mantiene desempeno robusto en horizonte temporal de 3 meses\")\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "print(\"FIN DE LA DEMOSTRACION TECNICA\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nSistema validado exitosamente con capacidad de despliegue en produccion.\")\n",
    "print(\"Mejoras cuantificables demostradas respecto al sistema baseline.\")\n",
    "print(\"Arquitectura escalable lista para integracion con plataforma FuelControl.\")\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82d51ce",
   "metadata": {},
   "source": [
    "### EXPORTACION DE RESULTADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5b932135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados exportados a: /home/leonard/Documents/proyecto de grado/fuel_theft_detection/data/reports/validacion_julio_2025_resultados.csv\n",
      "Metricas exportadas a: /home/leonard/Documents/proyecto de grado/fuel_theft_detection/data/reports/metricas_validacion_julio_2025.json\n",
      "\n",
      "DEMOSTRACION COMPLETADA EXITOSAMENTE\n"
     ]
    }
   ],
   "source": [
    "# Guardar resultados para reportes\n",
    "\n",
    "REPORTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# DataFrame de resultados batch\n",
    "results_df = new_data[[\n",
    "'timestamp', 'vehicle_id', 'pattern', 'drop_gal', 'duration_min',\n",
    "'is_night', 'is_hotspot', 'prob_robo', 'alerta_generada',\n",
    "'ground_truth', 'ground_truth_label'\n",
    "]].copy()\n",
    "results_path = REPORTS_DIR / \"validacion_julio_2025_resultados.csv\"\n",
    "results_df.to_csv(results_path, index=False)\n",
    "print(f\"Resultados exportados a: {results_path}\")\n",
    "\n",
    "# Metricas de validacion\n",
    "metrics_export = {\n",
    "'dataset': 'WOL991_julio_2025',\n",
    "'n_eventos': int(len(new_data)),\n",
    "'n_alertas': int(new_data['alerta_generada'].sum()),\n",
    "'precision': float(precision),\n",
    "'recall': float(recall),\n",
    "'f1_score': float(f1_score),\n",
    "'accuracy': float(accuracy),\n",
    "'fpr': float(fpr),\n",
    "'pr_auc': float(pr_auc_value),\n",
    "'roc_auc': float(roc_auc_value),\n",
    "'tp': int(tp),\n",
    "'fp': int(fp),\n",
    "'tn': int(tn),\n",
    "'fn': int(fn)\n",
    "}\n",
    "\n",
    "import json\n",
    "\n",
    "metrics_path = REPORTS_DIR / \"metricas_validacion_julio_2025.json\"\n",
    "with open(metrics_path, 'w') as f:\n",
    "    json.dump(metrics_export, f, indent=2)\n",
    "\n",
    "print(f\"Metricas exportadas a: {metrics_path}\")\n",
    "print(\"\\nDEMOSTRACION COMPLETADA EXITOSAMENTE\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
