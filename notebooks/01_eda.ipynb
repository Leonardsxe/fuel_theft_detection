{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exploratory Data Analysis - Fuel Theft Detection\n",
        "\n",
        "This notebook performs comprehensive exploratory data analysis on the fuel theft detection dataset.\n",
        "\n",
        "## Objectives\n",
        "1. Load and inspect combined dataset\n",
        "2. Analyze telemetry data patterns\n",
        "3. Visualize fuel level trends\n",
        "4. Identify potential theft events\n",
        "5. Examine vehicle behavior patterns\n",
        "6. Generate data quality report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from IPython.display import display  # ensure display(...) works\n",
        "\n",
        "# Add project root to path\n",
        "sys.path.insert(0, str(Path.cwd().parent))\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette('husl')\n",
        "%matplotlib inline\n",
        "\n",
        "# Configure pandas display\n",
        "pd.set_option('display.max_columns', 50)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.float_format', '{:.2f}'.format)\n",
        "\n",
        "print(\"\u2713 Libraries imported successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load combined dataset\n",
        "DATA_PATH = Path(\"../data/eda_outputs/combined_dataset.csv\")\n",
        "\n",
        "if not DATA_PATH.exists():\n",
        "    print(f\"\u274c Data not found: {DATA_PATH}\")\n",
        "    print(\"Run scripts/01_combine_datasets.py first!\")\n",
        "else:\n",
        "    df = pd.read_csv(DATA_PATH)\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "    \n",
        "    print(f\"\u2713 Loaded {len(df):,} rows from {DATA_PATH.name}\")\n",
        "    print(f\"  Vehicles: {df['vehicle_id'].nunique()}\")\n",
        "    print(f\"  Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
        "    print(f\"  Duration: {(df['timestamp'].max() - df['timestamp'].min()).days} days\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Basic Data Inspection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset overview\n",
        "print(\"Dataset Shape:\", df.shape)\n",
        "print(\"\\nColumn Names:\")\n",
        "print(df.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data types and missing values\n",
        "info_df = pd.DataFrame({\n",
        "    'dtype': df.dtypes,\n",
        "    'non_null': df.count(),\n",
        "    'null_count': df.isnull().sum(),\n",
        "    'null_pct': (df.isnull().sum() / len(df) * 100).round(2)\n",
        "})\n",
        "\n",
        "print(\"\\nData Types and Missing Values:\")\n",
        "display(info_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# First few rows\n",
        "print(\"\\nFirst 10 rows:\")\n",
        "display(df.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistical summary\n",
        "print(\"\\nStatistical Summary:\")\n",
        "display(df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Vehicle-Level Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Per-vehicle statistics\n",
        "vehicle_stats = df.groupby('vehicle_id').agg({\n",
        "    'timestamp': ['min', 'max', 'count'],\n",
        "    'total_fuel_gal': ['min', 'max', 'mean', 'std'],\n",
        "    'speed_kmh': ['mean', 'max'],\n",
        "    'latitude': 'count',\n",
        "    'ignition': lambda x: (x == True).sum()\n",
        "}).round(2)\n",
        "\n",
        "vehicle_stats.columns = ['_'.join(col).strip() for col in vehicle_stats.columns.values]\n",
        "vehicle_stats['duration_days'] = (\n",
        "    (vehicle_stats['timestamp_max'] - vehicle_stats['timestamp_min']).dt.days\n",
        ")\n",
        "\n",
        "print(\"Per-Vehicle Statistics:\")\n",
        "display(vehicle_stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize data points per vehicle\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Bar plot of records per vehicle\n",
        "vehicle_counts = df['vehicle_id'].value_counts().sort_index()\n",
        "axes[0].bar(vehicle_counts.index.astype(str), vehicle_counts.values)\n",
        "axes[0].set_xlabel('Vehicle ID')\n",
        "axes[0].set_ylabel('Number of Records')\n",
        "axes[0].set_title('Telemetry Records per Vehicle')\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Pie chart of data distribution\n",
        "axes[1].pie(vehicle_counts.values, labels=vehicle_counts.index, autopct='%1.1f%%')\n",
        "axes[1].set_title('Data Distribution by Vehicle')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Fuel Level Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fuel level distribution\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Overall distribution\n",
        "axes[0, 0].hist(df['total_fuel_gal'].dropna(), bins=50, edgecolor='black')\n",
        "axes[0, 0].set_xlabel('Fuel Level (gallons)')\n",
        "axes[0, 0].set_ylabel('Frequency')\n",
        "axes[0, 0].set_title('Overall Fuel Level Distribution')\n",
        "axes[0, 0].axvline(df['total_fuel_gal'].mean(), color='r', linestyle='--', label=f'Mean: {df[\"total_fuel_gal\"].mean():.1f}')\n",
        "axes[0, 0].legend()\n",
        "\n",
        "# Box plot per vehicle\n",
        "df.boxplot(column='total_fuel_gal', by='vehicle_id', ax=axes[0, 1])\n",
        "axes[0, 1].set_xlabel('Vehicle ID')\n",
        "axes[0, 1].set_ylabel('Fuel Level (gallons)')\n",
        "axes[0, 1].set_title('Fuel Level Distribution by Vehicle')\n",
        "plt.sca(axes[0, 1])\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Fuel changes (differences)\n",
        "df_sorted = df.sort_values(['vehicle_id', 'timestamp'])\n",
        "df_sorted['fuel_change'] = df_sorted.groupby('vehicle_id')['total_fuel_gal'].diff()\n",
        "\n",
        "axes[1, 0].hist(df_sorted['fuel_change'].dropna(), bins=100, edgecolor='black', range=(-50, 50))\n",
        "axes[1, 0].set_xlabel('Fuel Change (gallons)')\n",
        "axes[1, 0].set_ylabel('Frequency')\n",
        "axes[1, 0].set_title('Fuel Change Distribution (consecutive readings)')\n",
        "axes[1, 0].axvline(0, color='r', linestyle='--', linewidth=2)\n",
        "\n",
        "# Large negative changes (potential thefts)\n",
        "large_drops = df_sorted[df_sorted['fuel_change'] < -5]['fuel_change']\n",
        "axes[1, 1].hist(large_drops, bins=30, edgecolor='black', color='red', alpha=0.7)\n",
        "axes[1, 1].set_xlabel('Fuel Drop (gallons)')\n",
        "axes[1, 1].set_ylabel('Frequency')\n",
        "axes[1, 1].set_title(f'Large Fuel Drops (< -5 gal) - {len(large_drops):,} occurrences')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nFuel Change Statistics:\")\n",
        "print(f\"  Mean change: {df_sorted['fuel_change'].mean():.3f} gal\")\n",
        "print(f\"  Std dev: {df_sorted['fuel_change'].std():.3f} gal\")\n",
        "print(f\"  Large drops (< -5 gal): {len(large_drops):,}\")\n",
        "print(f\"  Max drop: {df_sorted['fuel_change'].min():.2f} gal\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Time Series Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot fuel levels over time for each vehicle\n",
        "vehicles = df['vehicle_id'].unique()\n",
        "n_vehicles = len(vehicles)\n",
        "\n",
        "fig, axes = plt.subplots(n_vehicles, 1, figsize=(15, 5*n_vehicles), sharex=False)\n",
        "\n",
        "if n_vehicles == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for idx, vehicle in enumerate(vehicles):\n",
        "    vehicle_data = df[df['vehicle_id'] == vehicle].sort_values('timestamp')\n",
        "    \n",
        "    axes[idx].plot(vehicle_data['timestamp'], vehicle_data['total_fuel_gal'], \n",
        "                   linewidth=0.5, alpha=0.7)\n",
        "    axes[idx].set_ylabel('Fuel Level (gal)')\n",
        "    axes[idx].set_title(f'Vehicle {vehicle} - Fuel Level Over Time')\n",
        "    axes[idx].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Highlight large drops\n",
        "    vehicle_data['fuel_change'] = vehicle_data['total_fuel_gal'].diff()\n",
        "    large_drops = vehicle_data[vehicle_data['fuel_change'] < -5]\n",
        "    \n",
        "    if len(large_drops) > 0:\n",
        "        axes[idx].scatter(large_drops['timestamp'], large_drops['total_fuel_gal'], \n",
        "                         color='red', s=50, zorder=5, label=f'{len(large_drops)} large drops')\n",
        "        axes[idx].legend()\n",
        "\n",
        "axes[-1].set_xlabel('Timestamp')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Speed and Movement Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Speed analysis\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Speed distribution\n",
        "axes[0, 0].hist(df['speed_kmh'].dropna(), bins=50, edgecolor='black')\n",
        "axes[0, 0].set_xlabel('Speed (km/h)')\n",
        "axes[0, 0].set_ylabel('Frequency')\n",
        "axes[0, 0].set_title('Speed Distribution')\n",
        "axes[0, 0].axvline(1, color='r', linestyle='--', label='Stationary threshold (1 km/h)')\n",
        "axes[0, 0].legend()\n",
        "\n",
        "# Speed vs Fuel level\n",
        "sample = df.sample(min(10000, len(df)))\n",
        "axes[0, 1].scatter(sample['speed_kmh'], sample['total_fuel_gal'], alpha=0.3, s=1)\n",
        "axes[0, 1].set_xlabel('Speed (km/h)')\n",
        "axes[0, 1].set_ylabel('Fuel Level (gal)')\n",
        "axes[0, 1].set_title('Speed vs Fuel Level')\n",
        "\n",
        "# Ignition status\n",
        "ignition_counts = df['ignition'].value_counts()\n",
        "axes[1, 0].bar(['Off', 'On'], [ignition_counts.get(False, 0), ignition_counts.get(True, 0)])\n",
        "axes[1, 0].set_ylabel('Count')\n",
        "axes[1, 0].set_title('Ignition Status Distribution')\n",
        "\n",
        "# Stationary vs Moving\n",
        "stationary = (df['speed_kmh'] <= 1).sum()\n",
        "moving = (df['speed_kmh'] > 1).sum()\n",
        "axes[1, 1].pie([stationary, moving], labels=['Stationary (\u22641 km/h)', 'Moving (>1 km/h)'], \n",
        "               autopct='%1.1f%%')\n",
        "axes[1, 1].set_title('Stationary vs Moving')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nMovement Statistics:\")\n",
        "print(f\"  Stationary points: {stationary:,} ({stationary/len(df)*100:.1f}%)\")\n",
        "print(f\"  Moving points: {moving:,} ({moving/len(df)*100:.1f}%)\")\n",
        "print(f\"  Mean speed: {df['speed_kmh'].mean():.2f} km/h\")\n",
        "print(f\"  Max speed: {df['speed_kmh'].max():.2f} km/h\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Geographic Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GPS coordinates analysis\n",
        "valid_coords = df.dropna(subset=['latitude', 'longitude'])\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Scatter plot of GPS coordinates (sample for performance)\n",
        "sample_size = min(50000, len(valid_coords))\n",
        "sample = valid_coords.sample(sample_size)\n",
        "\n",
        "vehicles = df['vehicle_id'].unique()\n",
        "for vehicle in vehicles:\n",
        "    vehicle_sample = sample[sample['vehicle_id'] == vehicle]\n",
        "    axes[0].scatter(vehicle_sample['longitude'], vehicle_sample['latitude'], \n",
        "                   alpha=0.3, s=1, label=f'Vehicle {vehicle}')\n",
        "\n",
        "axes[0].set_xlabel('Longitude')\n",
        "axes[0].set_ylabel('Latitude')\n",
        "axes[0].set_title(f'GPS Coordinates ({sample_size:,} points)')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Heatmap (2D histogram)\n",
        "h = axes[1].hist2d(sample['longitude'], sample['latitude'], bins=50, cmap='hot')\n",
        "axes[1].set_xlabel('Longitude')\n",
        "axes[1].set_ylabel('Latitude')\n",
        "axes[1].set_title('GPS Density Heatmap')\n",
        "plt.colorbar(h[3], ax=axes[1], label='Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nGeographic Statistics:\")\n",
        "print(f\"  Latitude range: {valid_coords['latitude'].min():.4f} to {valid_coords['latitude'].max():.4f}\")\n",
        "print(f\"  Longitude range: {valid_coords['longitude'].min():.4f} to {valid_coords['longitude'].max():.4f}\")\n",
        "print(f\"  Valid coordinates: {len(valid_coords):,} ({len(valid_coords)/len(df)*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Temporal Patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Temporal analysis\n",
        "df['hour'] = df['timestamp'].dt.hour\n",
        "df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
        "df['date'] = df['timestamp'].dt.date\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Hour of day distribution\n",
        "hour_counts = df['hour'].value_counts().sort_index()\n",
        "axes[0, 0].bar(hour_counts.index, hour_counts.values)\n",
        "axes[0, 0].set_xlabel('Hour of Day')\n",
        "axes[0, 0].set_ylabel('Number of Records')\n",
        "axes[0, 0].set_title('Data Distribution by Hour')\n",
        "axes[0, 0].set_xticks(range(0, 24, 2))\n",
        "\n",
        "# Day of week distribution\n",
        "dow_counts = df['day_of_week'].value_counts().sort_index()\n",
        "day_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
        "axes[0, 1].bar([day_names[i] for i in dow_counts.index], dow_counts.values)\n",
        "axes[0, 1].set_xlabel('Day of Week')\n",
        "axes[0, 1].set_ylabel('Number of Records')\n",
        "axes[0, 1].set_title('Data Distribution by Day of Week')\n",
        "\n",
        "# Daily record count\n",
        "daily_counts = df.groupby('date').size()\n",
        "axes[1, 0].plot(daily_counts.index, daily_counts.values)\n",
        "axes[1, 0].set_xlabel('Date')\n",
        "axes[1, 0].set_ylabel('Number of Records')\n",
        "axes[1, 0].set_title('Daily Record Count')\n",
        "axes[1, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Fuel drops by hour\n",
        "df_sorted = df.sort_values(['vehicle_id', 'timestamp'])\n",
        "df_sorted['fuel_change'] = df_sorted.groupby('vehicle_id')['total_fuel_gal'].diff()\n",
        "df_sorted['hour'] = df_sorted['timestamp'].dt.hour\n",
        "\n",
        "large_drops_by_hour = df_sorted[df_sorted['fuel_change'] < -5].groupby('hour').size()\n",
        "axes[1, 1].bar(large_drops_by_hour.index, large_drops_by_hour.values, color='red', alpha=0.7)\n",
        "axes[1, 1].set_xlabel('Hour of Day')\n",
        "axes[1, 1].set_ylabel('Number of Large Drops')\n",
        "axes[1, 1].set_title('Large Fuel Drops (< -5 gal) by Hour')\n",
        "axes[1, 1].set_xticks(range(0, 24, 2))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Data Quality Assessment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data quality metrics\n",
        "print(\"=\"*80)\n",
        "print(\"DATA QUALITY REPORT\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\n1. COMPLETENESS\")\n",
        "completeness = (1 - df.isnull().sum() / len(df)) * 100\n",
        "for col in df.columns:\n",
        "    status = \"\u2713\" if completeness[col] > 95 else \"\u26a0\" if completeness[col] > 80 else \"\u274c\"\n",
        "    print(f\"  {status} {col}: {completeness[col]:.2f}%\")\n",
        "\n",
        "print(f\"\\n2. VALIDITY\")\n",
        "valid_coords = df.dropna(subset=['latitude', 'longitude'])\n",
        "print(f\"  Coordinate validity: {(valid_coords.shape[0] / df.shape[0] * 100):.2f}%\")\n",
        "print(f\"  Speed validity: {((df['speed_kmh'] >= 0).sum() / len(df) * 100):.2f}%\")\n",
        "print(f\"  Fuel validity: {((df['total_fuel_gal'] >= 0).sum() / len(df) * 100):.2f}%\")\n",
        "\n",
        "print(f\"\\n3. CONSISTENCY\")\n",
        "# Check for duplicate timestamps per vehicle\n",
        "duplicates = df.duplicated(subset=['vehicle_id', 'timestamp']).sum()\n",
        "print(f\"  Duplicate timestamps: {duplicates} ({duplicates/len(df)*100:.3f}%)\")\n",
        "\n",
        "# Time gaps analysis\n",
        "df_sorted = df.sort_values(['vehicle_id', 'timestamp'])\n",
        "df_sorted['time_gap'] = df_sorted.groupby('vehicle_id')['timestamp'].diff().dt.total_seconds()\n",
        "large_gaps = (df_sorted['time_gap'] > 3600).sum()  # > 1 hour\n",
        "print(f\"  Large time gaps (>1h): {large_gaps:,}\")\n",
        "\n",
        "print(f\"\\n4. ANOMALIES\")\n",
        "print(f\"  Large fuel drops (< -5 gal): {(df_sorted['fuel_change'] < -5).sum():,}\")\n",
        "print(f\"  Large fuel increases (> 50 gal): {(df_sorted['fuel_change'] > 50).sum():,}\")\n",
        "print(f\"  Extreme speeds (> 120 km/h): {(df['speed_kmh'] > 120).sum():,}\")\n",
        "\n",
        "print(f\"\\n5. COVERAGE\")\n",
        "vehicles = df['vehicle_id'].unique()\n",
        "for vehicle in vehicles:\n",
        "    vehicle_data = df[df['vehicle_id'] == vehicle]\n",
        "    duration = (vehicle_data['timestamp'].max() - vehicle_data['timestamp'].min()).days\n",
        "    points_per_day = len(vehicle_data) / max(duration, 1)\n",
        "    print(f\"  Vehicle {vehicle}: {duration} days, {points_per_day:.1f} points/day\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Summary Statistics Export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive summary report\n",
        "summary_report = {\n",
        "    'dataset_info': {\n",
        "        'total_rows': len(df),\n",
        "        'num_vehicles': df['vehicle_id'].nunique(),\n",
        "        'date_range_start': str(df['timestamp'].min()),\n",
        "        'date_range_end': str(df['timestamp'].max()),\n",
        "        'duration_days': (df['timestamp'].max() - df['timestamp'].min()).days\n",
        "    },\n",
        "    'fuel_statistics': {\n",
        "        'mean_fuel_level': float(df['total_fuel_gal'].mean()),\n",
        "        'std_fuel_level': float(df['total_fuel_gal'].std()),\n",
        "        'min_fuel_level': float(df['total_fuel_gal'].min()),\n",
        "        'max_fuel_level': float(df['total_fuel_gal'].max()),\n",
        "        'large_drops_count': int((df_sorted['fuel_change'] < -5).sum())\n",
        "    },\n",
        "    'movement_statistics': {\n",
        "        'stationary_pct': float((df['speed_kmh'] <= 1).mean() * 100),\n",
        "        'mean_speed': float(df['speed_kmh'].mean()),\n",
        "        'max_speed': float(df['speed_kmh'].max())\n",
        "    },\n",
        "    'data_quality': {\n",
        "        'completeness_pct': float(completeness.mean()),\n",
        "        'valid_coords_pct': float(len(valid_coords) / len(df) * 100),\n",
        "        'duplicates_count': int(duplicates)\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save to JSON\n",
        "import json\n",
        "output_path = Path(\"../data/eda_outputs/eda_summary.json\")\n",
        "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "with open(output_path, 'w') as f:\n",
        "    json.dump(summary_report, f, indent=2)\n",
        "\n",
        "print(f\"\u2713 Summary report saved to: {output_path}\")\n",
        "\n",
        "# Optional: also export helpful tables\n",
        "try:\n",
        "    vehicle_stats.to_csv(output_path.parent / \"vehicle_stats.csv\")\n",
        "except NameError:\n",
        "    pass\n",
        "\n",
        "# Display summary\n",
        "from pprint import pprint\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"EDA SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "pprint(summary_report)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "title": "Exploratory Data Analysis - Fuel Theft Detection",
    "authors": [
      {
        "name": "Generated by ChatGPT"
      },
      {
        "name": "Date: 2025-10-30 23:05 UTC"
      }
    ]
  },
  "nbformat": 4,
  "nbformat_minor": 5
}