{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba0bed50",
   "metadata": {},
   "source": [
    "# Notebook 02: Feature Analysis\n",
    "## Feature Rationale & Diagnostic Validation\n",
    "\n",
    "### Objectives\n",
    "1. Justify the chosen feature set (link statistics to why features were retained)\n",
    "2. Demonstrate feature engineering impact (pre vs. post)\n",
    "3. Validate feature quality (distributions, correlations, vehicle-specific behavior)\n",
    "4. Identify most predictive features for theft detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455496f3",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9556da41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "from src.config.loader import load_config\n",
    "from src.features.engineering import FeatureEngineer\n",
    "from src.utils.timezone import ensure_series_utc\n",
    "\n",
    "config = load_config(\n",
    "    detection_config_path=Path(\"../config/detection_config.yaml\"),\n",
    "    model_config_path=Path(\"../config/model_config.yaml\"),\n",
    "    path_config_path=Path(\"../config/paths_config.yaml\")\n",
    ")\n",
    "\n",
    "# Load events (should have features already engineered from 03_train_models.py)\n",
    "events_df = pd.read_csv(config.paths.output.events_csv)\n",
    "events_df['start_time'] = pd.to_datetime(events_df['start_time'], utc=True)\n",
    "events_df['end_time'] = pd.to_datetime(events_df['end_time'], utc=True)\n",
    "\n",
    "# Load feature importance (from training)\n",
    "fi_path = Path(\"../data/reports/feature_importance.csv\")\n",
    "if fi_path.exists():\n",
    "    feature_importance = pd.read_csv(fi_path)\n",
    "else:\n",
    "    print(\"⚠️ Feature importance not found. Run 03_train_models.py first.\")\n",
    "    feature_importance = None\n",
    "\n",
    "print(f\"Loaded {len(events_df):,} events with {len([c for c in events_df.columns if c not in ['vehicle_id','start_time','end_time','pattern','y','is_train']])} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e39e899",
   "metadata": {},
   "source": [
    "## Section 1: Feature Categories & Purpose (5 minutes)\n",
    "\n",
    "### 1.1 Feature Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f493d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize features\n",
    "feature_categories = {\n",
    "    'Event Core': ['drop_gal', 'min_step_gal', 'duration_min', 'n_negative_steps', 'rate_gpm'],\n",
    "    'Event Quality': ['n_points', 'median_dt_s', 'p95_abs_dfuel', 'pct_ign_on'],\n",
    "    'Temporal': ['hod_sin', 'hod_cos', 'weekday', 'is_weekend', 'is_night'],\n",
    "    'Spatial': ['lat_c', 'lon_c', 'lat_std', 'lon_std', 'coord_range_km', 'window_trip_km'],\n",
    "    'Hotspot': ['is_hotspot', 'cluster_id', 'cluster_count'],\n",
    "    'Behavioral': ['pre_event_distance_km', 'pre_event_avg_speed', 'pre_event_moving_pct', \n",
    "                   'pre_event_fuel_change', 'speed_std', 'speed_max', 'movement_variability'],\n",
    "    'Vehicle-Normalized': ['drop_gal_vehicle_zscore', 'rate_gpm_vehicle_zscore', \n",
    "                           'min_step_gal_vehicle_zscore', 'duration_min_vehicle_zscore',\n",
    "                           'drop_pct_of_avg', 'drop_pct_of_max']\n",
    "}\n",
    "\n",
    "# Count available features per category\n",
    "for category, features in feature_categories.items():\n",
    "    available = [f for f in features if f in events_df.columns]\n",
    "    print(f\"{category:20s}: {len(available)}/{len(features)} available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e8c5b2",
   "metadata": {},
   "source": [
    "**Design Principle:**\n",
    "> Each feature category serves a specific purpose in the detection pipeline:\n",
    "> - **Event Core**: Fundamental theft characteristics (volume, rate, duration)\n",
    "> - **Event Quality**: Signal quality indicators (helps filter sensor noise)\n",
    "> - **Temporal**: Time-of-day patterns (night thefts more suspicious)\n",
    "> - **Spatial**: Location context (repeated locations = organized theft)\n",
    "> - **Hotspot**: Geospatial clustering (high-risk zones)\n",
    "> - **Behavioral**: Pre-event context (sudden stops after long drives = suspicious)\n",
    "> - **Vehicle-Normalized**: Account for vehicle-specific baselines (fleet heterogeneity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904f3562",
   "metadata": {},
   "source": [
    "## Section 2: Core Features - Impact Demonstration (15 minutes)\n",
    "\n",
    "### 2.1 drop_gal: Fuel Drop Volume\n",
    "**Rationale:** Primary indicator of theft magnitude. Larger drops more likely to be theft vs. consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221047a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Distribution\n",
    "axes[0].hist(events_df['drop_gal'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(events_df['drop_gal'].median(), color='red', linestyle='--', \n",
    "                label=f'Median: {events_df[\"drop_gal\"].median():.2f}gal')\n",
    "axes[0].set_xlabel('Fuel Drop (gallons)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('drop_gal Distribution')\n",
    "axes[0].legend()\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "# By pattern\n",
    "events_df.boxplot(column='drop_gal', by='pattern', ax=axes[1])\n",
    "axes[1].set_xlabel('Pattern')\n",
    "axes[1].set_ylabel('Fuel Drop (gal)')\n",
    "axes[1].set_title('drop_gal by Pattern')\n",
    "plt.sca(axes[1])\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Theft vs. Normal (if labels available)\n",
    "if 'y' in events_df.columns:\n",
    "    theft_drops = events_df[events_df['y'] == 1]['drop_gal']\n",
    "    normal_drops = events_df[events_df['y'] == 0]['drop_gal']\n",
    "    \n",
    "    axes[2].hist(normal_drops, bins=30, alpha=0.6, label='Normal', color='blue')\n",
    "    axes[2].hist(theft_drops, bins=30, alpha=0.6, label='Theft', color='red')\n",
    "    axes[2].set_xlabel('Fuel Drop (gal)')\n",
    "    axes[2].set_ylabel('Frequency')\n",
    "    axes[2].set_title('drop_gal: Theft vs. Normal')\n",
    "    axes[2].legend()\n",
    "    axes[2].set_yscale('log')\n",
    "    \n",
    "    # Statistical test\n",
    "    stat, pval = stats.mannwhitneyu(theft_drops, normal_drops, alternative='greater')\n",
    "    print(f\"Mann-Whitney U test: statistic={stat:.2f}, p-value={pval:.2e}\")\n",
    "    print(f\"Median drop - Theft: {theft_drops.median():.2f}gal, Normal: {normal_drops.median():.2f}gal\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6231facd",
   "metadata": {},
   "source": [
    "### 2.2 rate_gpm: Fuel Drop Rate\n",
    "**Rationale:** Distinguishes theft (rapid) from consumption (gradual). High rates impossible via normal operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8d4d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Rate distribution with thresholds\n",
    "axes[0].hist(events_df['rate_gpm'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(0.5, color='orange', linestyle='--', label='Typical consumption rate')\n",
    "axes[0].axvline(2.0, color='red', linestyle='--', label='Max plausible rate (config)')\n",
    "axes[0].set_xlabel('Rate (gal/min)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('rate_gpm Distribution')\n",
    "axes[0].set_xlim(0, min(5, events_df['rate_gpm'].quantile(0.99)))\n",
    "axes[0].legend()\n",
    "\n",
    "# Scatterplot: drop vs. rate (colored by theft status)\n",
    "if 'y' in events_df.columns:\n",
    "    scatter = axes[1].scatter(events_df['drop_gal'], events_df['rate_gpm'], \n",
    "                             c=events_df['y'], cmap='RdYlGn_r', alpha=0.6, s=20)\n",
    "    axes[1].set_xlabel('Fuel Drop (gal)')\n",
    "    axes[1].set_ylabel('Rate (gal/min)')\n",
    "    axes[1].set_title('Drop Volume vs. Rate (colored by theft label)')\n",
    "    axes[1].set_ylim(0, min(3, events_df['rate_gpm'].quantile(0.99)))\n",
    "    plt.colorbar(scatter, ax=axes[1], label='Theft')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a38a5e",
   "metadata": {},
   "source": [
    "**Key Finding:**\n",
    "> Events with rate > 1.0 gal/min are [X]x more likely to be confirmed thefts (odds ratio)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d44dbe",
   "metadata": {},
   "source": [
    "## Section 3: Temporal Features - Night Effect (10 minutes)\n",
    "\n",
    "### 3.1 Hour-of-Day Cyclical Encoding\n",
    "**Rationale:** Thefts exhibit temporal patterns (e.g., overnight when supervision is low). Cyclical encoding (sin/cos) preserves 23→0 hour continuity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102db6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Calculate hour from midpoint\n",
    "events_df['mid_time'] = events_df['start_time'] + (events_df['end_time'] - events_df['start_time'])/2\n",
    "events_df['hour'] = events_df['mid_time'].dt.hour + events_df['mid_time'].dt.minute/60\n",
    "\n",
    "# Hour distribution\n",
    "axes[0].hist(events_df['hour'], bins=24, edgecolor='black', alpha=0.7, range=(0,24))\n",
    "axes[0].set_xlabel('Hour of Day')\n",
    "axes[0].set_ylabel('Event Count')\n",
    "axes[0].set_title('Event Distribution by Hour')\n",
    "axes[0].axvspan(22, 24, alpha=0.2, color='navy', label='Night (22:00-05:59)')\n",
    "axes[0].axvspan(0, 6, alpha=0.2, color='navy')\n",
    "axes[0].legend()\n",
    "\n",
    "# Theft rate by hour (if labels available)\n",
    "if 'y' in events_df.columns:\n",
    "    hour_bins = pd.cut(events_df['hour'], bins=24, labels=range(24))\n",
    "    theft_rate_by_hour = events_df.groupby(hour_bins)['y'].mean()\n",
    "    \n",
    "    axes[1].bar(range(24), theft_rate_by_hour, edgecolor='black', alpha=0.7)\n",
    "    axes[1].axvspan(22, 24, alpha=0.2, color='navy')\n",
    "    axes[1].axvspan(0, 6, alpha=0.2, color='navy')\n",
    "    axes[1].set_xlabel('Hour of Day')\n",
    "    axes[1].set_ylabel('Theft Rate')\n",
    "    axes[1].set_title('Confirmed Theft Rate by Hour')\n",
    "    axes[1].set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Statistical comparison: night vs. day\n",
    "if 'y' in events_df.columns and 'is_night' in events_df.columns:\n",
    "    night_theft_rate = events_df[events_df['is_night'] == 1]['y'].mean()\n",
    "    day_theft_rate = events_df[events_df['is_night'] == 0]['y'].mean()\n",
    "    print(f\"Night theft rate: {night_theft_rate:.2%}\")\n",
    "    print(f\"Day theft rate: {day_theft_rate:.2%}\")\n",
    "    print(f\"Night/Day theft rate ratio: {night_theft_rate/day_theft_rate:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0738997",
   "metadata": {},
   "source": [
    "## Section 4: Behavioral Features - Pre-Event Context (15 minutes)\n",
    "\n",
    "### 4.1 Pre-Event Distance (2-hour lookback)\n",
    "**Rationale:** Thefts after long journeys may indicate planned stops at vulnerable locations. Post-journey exhaustion/inattention exploited by thieves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9767df",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Distribution\n",
    "axes[0,0].hist(events_df['pre_event_distance_km'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0,0].axvline(events_df['pre_event_distance_km'].median(), color='red', linestyle='--',\n",
    "                  label=f'Median: {events_df[\"pre_event_distance_km\"].median():.1f}km')\n",
    "axes[0,0].set_xlabel('Pre-Event Distance (km, 2h lookback)')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "axes[0,0].set_title('Pre-Event Distance Distribution')\n",
    "axes[0,0].legend()\n",
    "\n",
    "# By pattern\n",
    "events_df.boxplot(column='pre_event_distance_km', by='pattern', ax=axes[0,1])\n",
    "axes[0,1].set_xlabel('Pattern')\n",
    "axes[0,1].set_ylabel('Pre-Event Distance (km)')\n",
    "axes[0,1].set_title('Pre-Event Distance by Pattern')\n",
    "plt.sca(axes[0,1])\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Theft vs. Normal\n",
    "if 'y' in events_df.columns:\n",
    "    theft_dist = events_df[events_df['y'] == 1]['pre_event_distance_km']\n",
    "    normal_dist = events_df[events_df['y'] == 0]['pre_event_distance_km']\n",
    "    \n",
    "    axes[1,0].hist(normal_dist, bins=30, alpha=0.6, label='Normal', color='blue')\n",
    "    axes[1,0].hist(theft_dist, bins=30, alpha=0.6, label='Theft', color='red')\n",
    "    axes[1,0].set_xlabel('Pre-Event Distance (km)')\n",
    "    axes[1,0].set_ylabel('Frequency')\n",
    "    axes[1,0].set_title('Pre-Event Distance: Theft vs. Normal')\n",
    "    axes[1,0].legend()\n",
    "    \n",
    "    # Statistical test\n",
    "    stat, pval = stats.mannwhitneyu(theft_dist.dropna(), normal_dist.dropna())\n",
    "    print(f\"Pre-Event Distance - Mann-Whitney U: p={pval:.3f}\")\n",
    "    print(f\"  Theft median: {theft_dist.median():.1f}km, Normal median: {normal_dist.median():.1f}km\")\n",
    "\n",
    "# Pre-event fuel change\n",
    "axes[1,1].scatter(events_df['pre_event_distance_km'], events_df['pre_event_fuel_change'],\n",
    "                 alpha=0.5, s=10)\n",
    "axes[1,1].set_xlabel('Pre-Event Distance (km)')\n",
    "axes[1,1].set_ylabel('Pre-Event Fuel Change (gal)')\n",
    "axes[1,1].set_title('Pre-Event Distance vs. Fuel Change')\n",
    "axes[1,1].axhline(0, color='red', linestyle='--', linewidth=1)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ace27d",
   "metadata": {},
   "source": [
    "### 4.2 Movement Variability\n",
    "**Rationale:** Sudden stops (low variability) vs. gradual slowdowns. Abrupt stops may indicate intentional parking for theft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1eeb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "if 'y' in events_df.columns:\n",
    "    theft_var = events_df[events_df['y'] == 1]['movement_variability']\n",
    "    normal_var = events_df[events_df['y'] == 0]['movement_variability']\n",
    "    \n",
    "    ax.hist(normal_var, bins=30, alpha=0.6, label='Normal', color='blue')\n",
    "    ax.hist(theft_var, bins=30, alpha=0.6, label='Theft', color='red')\n",
    "    ax.set_xlabel('Movement Variability (speed variance)')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title('Movement Variability: Theft vs. Normal')\n",
    "    ax.set_yscale('log')\n",
    "    ax.legend()\n",
    "    \n",
    "    print(f\"Movement Variability - Theft median: {theft_var.median():.2f}, Normal median: {normal_var.median():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172dce8e",
   "metadata": {},
   "source": [
    "## Section 5: Vehicle-Normalized Features (10 minutes)\n",
    "\n",
    "### 5.1 Why Vehicle Normalization Matters\n",
    "**Problem:** Fleet heterogeneity (trucks vs. vans, different tank sizes). 5-gallon drop = minor for truck, major for van."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfaaeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: drop_gal vs. drop_pct_of_avg for 3 vehicles\n",
    "example_vids = events_df['vehicle_id'].value_counts().head(3).index\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for vid in example_vids:\n",
    "    vid_events = events_df[events_df['vehicle_id'] == vid]\n",
    "    axes[0].scatter(vid_events.index, vid_events['drop_gal'], label=f'Vehicle {vid}', alpha=0.7)\n",
    "    axes[1].scatter(vid_events.index, vid_events['drop_pct_of_avg'], label=f'Vehicle {vid}', alpha=0.7)\n",
    "\n",
    "axes[0].set_xlabel('Event Index')\n",
    "axes[0].set_ylabel('Absolute Drop (gal)')\n",
    "axes[0].set_title('Absolute Fuel Drop (not vehicle-normalized)')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].set_xlabel('Event Index')\n",
    "axes[1].set_ylabel('Drop as % of Vehicle Avg Fuel')\n",
    "axes[1].set_title('Normalized Drop (% of vehicle average)')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85811166",
   "metadata": {},
   "source": [
    "**Key Insight:**\n",
    "> Without normalization, model biases toward vehicles with larger tanks. Normalization ensures equal treatment across fleet.\n",
    "\n",
    "### 5.2 Z-Score Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d528e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation: raw vs. z-scored features\n",
    "features_to_compare = [\n",
    "    ('drop_gal', 'drop_gal_vehicle_zscore'),\n",
    "    ('rate_gpm', 'rate_gpm_vehicle_zscore'),\n",
    "    ('duration_min', 'duration_min_vehicle_zscore')\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "for i, (raw, zscore) in enumerate(features_to_compare):\n",
    "    if zscore in events_df.columns:\n",
    "        axes[i].scatter(events_df[raw], events_df[zscore], alpha=0.5, s=10)\n",
    "        axes[i].set_xlabel(f'{raw} (raw)')\n",
    "        axes[i].set_ylabel(f'{zscore}')\n",
    "        axes[i].set_title(f'Raw vs. Vehicle Z-Score: {raw}')\n",
    "        \n",
    "        # Correlation\n",
    "        corr = events_df[[raw, zscore]].corr().iloc[0,1]\n",
    "        axes[i].text(0.05, 0.95, f'ρ = {corr:.3f}', \n",
    "                    transform=axes[i].transAxes, fontsize=12, verticalalignment='top')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf7d29c",
   "metadata": {},
   "source": [
    "## Section 6: Feature Importance from Trained Models (10 minutes)\n",
    "\n",
    "### 6.1 Top 20 Features (from Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2567e45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if feature_importance is not None:\n",
    "    top_features = feature_importance.head(20)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    ax.barh(range(len(top_features)), top_features['importance'], color='steelblue')\n",
    "    ax.set_yticks(range(len(top_features)))\n",
    "    ax.set_yticklabels(top_features['feature'])\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel('Feature Importance')\n",
    "    ax.set_title('Top 20 Features - Random Forest')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac8f8de",
   "metadata": {},
   "source": [
    "**Interpretation Guide:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621fcda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if feature_importance is not None:\n",
    "    # Categorize top features\n",
    "    top_20_features = feature_importance.head(20)['feature'].tolist()\n",
    "    \n",
    "    categorized_top = {}\n",
    "    for category, features in feature_categories.items():\n",
    "        categorized_top[category] = [f for f in top_20_features if f in features]\n",
    "    \n",
    "    print(\"\\nTop 20 Features by Category:\")\n",
    "    for category, features in categorized_top.items():\n",
    "        if features:\n",
    "            print(f\"  {category}: {len(features)} features\")\n",
    "            for f in features:\n",
    "                importance = feature_importance[feature_importance['feature'] == f]['importance'].values[0]\n",
    "                print(f\"    - {f}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597dfd43",
   "metadata": {},
   "source": [
    "### 6.2 Feature Correlation Matrix (Top Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acda3aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "if feature_importance is not None:\n",
    "    # Select top 15 features for correlation analysis\n",
    "    top_15_features = feature_importance.head(15)['feature'].tolist()\n",
    "    available_features = [f for f in top_15_features if f in events_df.columns]\n",
    "    \n",
    "    if available_features:\n",
    "        corr_matrix = events_df[available_features].corr()\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 10))\n",
    "        sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "                   vmin=-1, vmax=1, center=0, ax=ax, square=True)\n",
    "        ax.set_title('Feature Correlation Matrix (Top 15 Features)')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Identify highly correlated pairs\n",
    "        high_corr_pairs = []\n",
    "        for i in range(len(corr_matrix.columns)):\n",
    "            for j in range(i+1, len(corr_matrix.columns)):\n",
    "                corr_val = corr_matrix.iloc[i, j]\n",
    "                if abs(corr_val) > 0.7:\n",
    "                    high_corr_pairs.append((\n",
    "                        corr_matrix.columns[i],\n",
    "                        corr_matrix.columns[j],\n",
    "                        corr_val\n",
    "                    ))\n",
    "        \n",
    "        if high_corr_pairs:\n",
    "            print(\"\\n⚠️ Highly correlated feature pairs (|ρ| > 0.7):\")\n",
    "            for f1, f2, corr in high_corr_pairs:\n",
    "                print(f\"  {f1} ↔ {f2}: ρ = {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3ca1a0",
   "metadata": {},
   "source": [
    "## Section 7: Feature Quality Diagnostics (10 minutes)\n",
    "\n",
    "### 7.1 Missing Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c8b53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [c for c in events_df.select_dtypes(include=[np.number]).columns \n",
    "                   if c not in ['vehicle_id', 'cluster_id', 'y', 'is_train']]\n",
    "\n",
    "missing_pct = events_df[numeric_features].isnull().sum() / len(events_df) * 100\n",
    "missing_pct = missing_pct[missing_pct > 0].sort_values(ascending=False)\n",
    "\n",
    "if not missing_pct.empty:\n",
    "    fig, ax = plt.subplots(figsize=(10, max(6, len(missing_pct)*0.3)))\n",
    "    ax.barh(range(len(missing_pct)), missing_pct.values, color='coral')\n",
    "    ax.set_yticks(range(len(missing_pct)))\n",
    "    ax.set_yticklabels(missing_pct.index)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel('Missing Percentage (%)')\n",
    "    ax.set_title('Features with Missing Values')\n",
    "    ax.axvline(5, color='red', linestyle='--', label='5% threshold')\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    print(f\"Features with >5% missing: {(missing_pct > 5).sum()}\")\n",
    "else:\n",
    "    print(\"✅ No missing values in numeric features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa3fb3b",
   "metadata": {},
   "source": [
    "### 7.2 Outlier Detection (IQR Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776a829d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for extreme outliers in key features\n",
    "key_features = ['drop_gal', 'rate_gpm', 'duration_min', 'pre_event_distance_km']\n",
    "available_key = [f for f in key_features if f in events_df.columns]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(available_key):\n",
    "    data = events_df[feature].dropna()\n",
    "    \n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 3*IQR  # 3*IQR for extreme outliers\n",
    "    upper_bound = Q3 + 3*IQR\n",
    "    \n",
    "    outliers = data[(data < lower_bound) | (data > upper_bound)]\n",
    "    outlier_pct = len(outliers) / len(data) * 100\n",
    "    \n",
    "    axes[i].boxplot(data, vert=False)\n",
    "    axes[i].set_xlabel(feature)\n",
    "    axes[i].set_title(f'{feature} - {outlier_pct:.1f}% extreme outliers')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9343b114",
   "metadata": {},
   "source": [
    "## Section 8: Summary & Recommendations\n",
    "\n",
    "### 8.1 Feature Retention Justification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a93f44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if feature_importance is not None:\n",
    "    # Cumulative importance\n",
    "    feature_importance['cumulative_importance'] = feature_importance['importance'].cumsum() / feature_importance['importance'].sum()\n",
    "    \n",
    "    # Find features contributing to 90% of total importance\n",
    "    n_features_90pct = (feature_importance['cumulative_importance'] <= 0.90).sum()\n",
    "    \n",
    "    print(f\"Features needed for 90% cumulative importance: {n_features_90pct}/{len(feature_importance)}\")\n",
    "    print(f\"Current feature set: {len([c for c in events_df.columns if c not in ['vehicle_id','start_time','end_time','pattern','y','is_train']])} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ec5144",
   "metadata": {},
   "source": [
    "**Recommendation:**\n",
    "> - **Core retention:** Top 20 features capture [X]% of predictive power\n",
    "> - **Behavioral features** (pre-event context) show [Y]% lift in PR-AUC vs. baseline\n",
    "> - **Vehicle normalization** reduces model bias by [Z]%\n",
    "> - **Temporal features** justify night-shift monitoring priority\n",
    "\n",
    "### 8.2 Feature Engineering Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44319749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performance with/without feature groups (requires re-training)\n",
    "# This is conceptual - actual comparison would need separate training runs\n",
    "\n",
    "impact_summary = pd.DataFrame({\n",
    "    'Feature Group': ['Core Only', '+ Temporal', '+ Behavioral', '+ Vehicle-Normalized', 'All Features'],\n",
    "    'Estimated PR-AUC': [0.65, 0.72, 0.78, 0.82, 0.85],  # Example values\n",
    "    'Lift vs. Core': [0.00, 0.07, 0.13, 0.17, 0.20]\n",
    "})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.barh(impact_summary['Feature Group'], impact_summary['Estimated PR-AUC'], color='steelblue')\n",
    "ax.set_xlabel('PR-AUC')\n",
    "ax.set_title('Feature Engineering Impact on Model Performance')\n",
    "ax.set_xlim(0.5, 1.0)\n",
    "plt.tight_layout()\n",
    "\n",
    "print(\"\\n\" + impact_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bfecab",
   "metadata": {},
   "source": [
    "## Export Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24506be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save feature statistics\n",
    "feature_stats = events_df[numeric_features].describe().T\n",
    "feature_stats.to_csv('../data/reports/feature_statistics.csv')\n",
    "\n",
    "# Save correlation matrix\n",
    "if feature_importance is not None and available_features:\n",
    "    corr_matrix.to_csv('../data/reports/feature_correlations.csv')\n",
    "\n",
    "print(\"✅ Feature analysis complete. Artifacts saved to data/reports/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
